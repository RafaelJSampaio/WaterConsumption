{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Consumtion in Sorono\n",
    "## Stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage I have divided the data table to one main and three child tables that will be joined through primary-foriegn keys.\n",
    "- The main table, I removed all text from it and placed foriegn keys instead\n",
    "- The other three tables I have hot-encoded them, each with its suitable encoding\n",
    "   - The `Usage` table was encoded based on the properties of its values.\n",
    "   - The `User` table was encoded based on the properties of its values.\n",
    "   - The `Gauge` table was encoded based on teh one-hot-encoding method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Case</th>\n",
       "      <th>Usage_ref</th>\n",
       "      <th>User_ref</th>\n",
       "      <th>Gauge_ref</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9096971</th>\n",
       "      <td>211</td>\n",
       "      <td>718</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>814</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682989</th>\n",
       "      <td>441</td>\n",
       "      <td>10279</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1415</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10100951</th>\n",
       "      <td>441</td>\n",
       "      <td>8757</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Condition   Case  Usage_ref  User_ref  Gauge_ref  Diameter  Year  \\\n",
       "9096971         211    718          3         6          1       0.5    14   \n",
       "4682989         441  10279          5         4          1       0.5    11   \n",
       "10100951        441   8757          5         4          1       0.5    15   \n",
       "\n",
       "          Month  Reference  Consumption  \n",
       "9096971       6        814           19  \n",
       "4682989      10       1415           25  \n",
       "10100951      1       1029           16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the tables\n",
    "main_df = pd.read_csv('Aqua_ref.CSV.gz', compression='gzip')\n",
    "main_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage_id</th>\n",
       "      <th>Usage_text</th>\n",
       "      <th>industry</th>\n",
       "      <th>housing</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>commerce</th>\n",
       "      <th>reserve</th>\n",
       "      <th>government</th>\n",
       "      <th>low_density</th>\n",
       "      <th>mid_density</th>\n",
       "      <th>high_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Government Reserve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Medium Risk Industry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Usage_id            Usage_text  industry  housing  agriculture  commerce  \\\n",
       "0         0              Downtown         0        1            0         1   \n",
       "1         1    Government Reserve         0        0            0         0   \n",
       "8         8  Medium Risk Industry         1        0            0         0   \n",
       "\n",
       "   reserve  government  low_density  mid_density  high_density  \n",
       "0        0           0            0            0             0  \n",
       "1        1           1            0            0             0  \n",
       "8        0           0            0            1             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>User_text</th>\n",
       "      <th>u_industry</th>\n",
       "      <th>u_domestic</th>\n",
       "      <th>u_social</th>\n",
       "      <th>u_commerce</th>\n",
       "      <th>u_low_density</th>\n",
       "      <th>u_mid_density</th>\n",
       "      <th>u_high_density</th>\n",
       "      <th>u_residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Medium Domestic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Residential Domestic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id             User_text  u_industry  u_domestic  u_social  \\\n",
       "4        4       Medium Domestic           0           1         0   \n",
       "2        2            Industrial           1           0         0   \n",
       "5        5  Residential Domestic           0           1         0   \n",
       "\n",
       "   u_commerce  u_low_density  u_mid_density  u_high_density  u_residential  \n",
       "4           0              0              1               0              0  \n",
       "2           0              0              0               0              0  \n",
       "5           0              0              0               0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gauge_id</th>\n",
       "      <th>Gauge_text</th>\n",
       "      <th>Gauge_names</th>\n",
       "      <th>Gauge_Abb</th>\n",
       "      <th>Gauge_Actaris</th>\n",
       "      <th>Gauge_Adcom</th>\n",
       "      <th>Gauge_Alfa</th>\n",
       "      <th>Gauge_Aquarius</th>\n",
       "      <th>Gauge_Arad</th>\n",
       "      <th>Gauge_Av3Stars</th>\n",
       "      <th>...</th>\n",
       "      <th>Gauge_Otras_Desconocida</th>\n",
       "      <th>Gauge_Precisa_Ii</th>\n",
       "      <th>Gauge_Recordal</th>\n",
       "      <th>Gauge_Sappel</th>\n",
       "      <th>Gauge_Sappel_Aquarius</th>\n",
       "      <th>Gauge_Sensus</th>\n",
       "      <th>Gauge_Shlumberger</th>\n",
       "      <th>Gauge_Tonhy</th>\n",
       "      <th>Gauge_Yt_Md15</th>\n",
       "      <th>Gauge_Zenner_Half_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>PRECISA II</td>\n",
       "      <td>Precisa_Ii</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Kent ABB</td>\n",
       "      <td>Kent_Abb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Cicasa NG 1/2</td>\n",
       "      <td>Cicasa_Ng_Half_In</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gauge_id     Gauge_text        Gauge_names  Gauge_Abb  Gauge_Actaris  \\\n",
       "36        36     PRECISA II         Precisa_Ii          0              0   \n",
       "34        34       Kent ABB           Kent_Abb          0              0   \n",
       "8          8  Cicasa NG 1/2  Cicasa_Ng_Half_In          0              0   \n",
       "\n",
       "    Gauge_Adcom  Gauge_Alfa  Gauge_Aquarius  Gauge_Arad  Gauge_Av3Stars  \\\n",
       "36            0           0               0           0               0   \n",
       "34            0           0               0           0               0   \n",
       "8             0           0               0           0               0   \n",
       "\n",
       "            ...           Gauge_Otras_Desconocida  Gauge_Precisa_Ii  \\\n",
       "36          ...                                 0                 1   \n",
       "34          ...                                 0                 0   \n",
       "8           ...                                 0                 0   \n",
       "\n",
       "    Gauge_Recordal  Gauge_Sappel  Gauge_Sappel_Aquarius  Gauge_Sensus  \\\n",
       "36               0             0                      0             0   \n",
       "34               0             0                      0             0   \n",
       "8                0             0                      0             0   \n",
       "\n",
       "    Gauge_Shlumberger  Gauge_Tonhy  Gauge_Yt_Md15  Gauge_Zenner_Half_In  \n",
       "36                  0            0              0                     0  \n",
       "34                  0            0              0                     0  \n",
       "8                   0            0              0                     0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Usage_df = pd.read_csv('Usage_encoded.CSV')\n",
    "User_df = pd.read_csv('User_encoded.CSV')\n",
    "Gauge_df = pd.read_csv('Gauge_encoded.CSV')\n",
    "display(Usage_df.sample(3), User_df.sample(3), Gauge_df.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df.merge(Usage_df, \n",
    "      left_on='Usage_ref', right_on='Usage_id', \n",
    "      how='outer').drop(columns=['Usage_ref', \n",
    "                                 'Usage_id', 'Usage_text']).merge(User_df, \n",
    "      left_on='User_ref', right_on='User_id', \n",
    "      how='outer').drop(columns=['User_ref', \n",
    "                                 'User_id', 'User_text']).merge(Gauge_df, \n",
    "      left_on='Gauge_ref', right_on='Gauge_id', \n",
    "      how='outer').drop(columns=['Gauge_ref',\n",
    "                                 'Gauge_id', 'Gauge_text', 'Gauge_names'])#.rename( \\\n",
    "      #columns={'Usage_text':'Usage', 'User_text':'User', 'Gauge_text':'Gauge',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to freeup the memory\n",
    "main_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Case</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>industry</th>\n",
       "      <th>housing</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>...</th>\n",
       "      <th>Gauge_Otras_Desconocida</th>\n",
       "      <th>Gauge_Precisa_Ii</th>\n",
       "      <th>Gauge_Recordal</th>\n",
       "      <th>Gauge_Sappel</th>\n",
       "      <th>Gauge_Sappel_Aquarius</th>\n",
       "      <th>Gauge_Sensus</th>\n",
       "      <th>Gauge_Shlumberger</th>\n",
       "      <th>Gauge_Tonhy</th>\n",
       "      <th>Gauge_Yt_Md15</th>\n",
       "      <th>Gauge_Zenner_Half_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1324365</th>\n",
       "      <td>149</td>\n",
       "      <td>13889</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512045</th>\n",
       "      <td>164</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131194</th>\n",
       "      <td>196</td>\n",
       "      <td>305</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954192</th>\n",
       "      <td>441</td>\n",
       "      <td>5769</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923813</th>\n",
       "      <td>774</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>159</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238618</th>\n",
       "      <td>281</td>\n",
       "      <td>583</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>392</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260263</th>\n",
       "      <td>144</td>\n",
       "      <td>791</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175574</th>\n",
       "      <td>149</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>420</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717669</th>\n",
       "      <td>197</td>\n",
       "      <td>935</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757291</th>\n",
       "      <td>455</td>\n",
       "      <td>3964</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>474</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Condition   Case  Diameter  Year  Month  Reference  Consumption  \\\n",
       "1324365         149  13889       0.5    11      8        900           20   \n",
       "8512045         164   1984       0.5    11     10          0            6   \n",
       "6131194         196    305       0.5    15     10         31           10   \n",
       "2954192         441   5769       0.5    13      1        655           10   \n",
       "5923813         774    300       0.5    13     11        159           24   \n",
       "2238618         281    583       0.5     9      9        392           15   \n",
       "11260263        144    791       0.5    14      5       1805            1   \n",
       "2175574         149   6548       0.5    15     10        420           19   \n",
       "9717669         197    935       0.5    12      5          0            0   \n",
       "5757291         455   3964       0.5    14     11        474           21   \n",
       "\n",
       "          industry  housing  agriculture          ...           \\\n",
       "1324365          0        1            0          ...            \n",
       "8512045          0        1            0          ...            \n",
       "6131194          0        1            0          ...            \n",
       "2954192          0        1            0          ...            \n",
       "5923813          1        1            0          ...            \n",
       "2238618          0        1            0          ...            \n",
       "11260263         0        1            0          ...            \n",
       "2175574          0        1            0          ...            \n",
       "9717669          0        1            0          ...            \n",
       "5757291          0        1            0          ...            \n",
       "\n",
       "          Gauge_Otras_Desconocida  Gauge_Precisa_Ii  Gauge_Recordal  \\\n",
       "1324365                         0                 0               0   \n",
       "8512045                         0                 0               0   \n",
       "6131194                         0                 0               0   \n",
       "2954192                         0                 0               0   \n",
       "5923813                         0                 0               0   \n",
       "2238618                         0                 0               0   \n",
       "11260263                        0                 0               0   \n",
       "2175574                         0                 0               0   \n",
       "9717669                         0                 0               0   \n",
       "5757291                         0                 0               0   \n",
       "\n",
       "          Gauge_Sappel  Gauge_Sappel_Aquarius  Gauge_Sensus  \\\n",
       "1324365              0                      0             0   \n",
       "8512045              0                      0             0   \n",
       "6131194              0                      0             0   \n",
       "2954192              0                      0             0   \n",
       "5923813              0                      0             0   \n",
       "2238618              0                      0             0   \n",
       "11260263             0                      0             0   \n",
       "2175574              0                      0             0   \n",
       "9717669              0                      0             0   \n",
       "5757291              0                      0             0   \n",
       "\n",
       "          Gauge_Shlumberger  Gauge_Tonhy  Gauge_Yt_Md15  Gauge_Zenner_Half_In  \n",
       "1324365                   0            0              0                     0  \n",
       "8512045                   0            0              0                     0  \n",
       "6131194                   0            0              0                     0  \n",
       "2954192                   0            0              0                     0  \n",
       "5923813                   0            0              0                     0  \n",
       "2238618                   0            0              0                     0  \n",
       "11260263                  0            0              0                     0  \n",
       "2175574                   0            0              0                     0  \n",
       "9717669                   0            0              0                     0  \n",
       "5757291                   0            0              0                     0  \n",
       "\n",
       "[10 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Case</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>industry</th>\n",
       "      <th>housing</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>...</th>\n",
       "      <th>Gauge_Otras_Desconocida</th>\n",
       "      <th>Gauge_Precisa_Ii</th>\n",
       "      <th>Gauge_Recordal</th>\n",
       "      <th>Gauge_Sappel</th>\n",
       "      <th>Gauge_Sappel_Aquarius</th>\n",
       "      <th>Gauge_Sensus</th>\n",
       "      <th>Gauge_Shlumberger</th>\n",
       "      <th>Gauge_Tonhy</th>\n",
       "      <th>Gauge_Yt_Md15</th>\n",
       "      <th>Gauge_Zenner_Half_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "      <td>1.167268e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.355588e+02</td>\n",
       "      <td>2.809605e+03</td>\n",
       "      <td>5.031340e-01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.499998e+00</td>\n",
       "      <td>1.391269e+03</td>\n",
       "      <td>1.757733e+01</td>\n",
       "      <td>1.122546e-01</td>\n",
       "      <td>9.972798e-01</td>\n",
       "      <td>1.468044e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.155290e-02</td>\n",
       "      <td>1.151407e-04</td>\n",
       "      <td>1.223370e-04</td>\n",
       "      <td>8.563590e-04</td>\n",
       "      <td>2.878518e-05</td>\n",
       "      <td>5.598717e-03</td>\n",
       "      <td>3.218902e-02</td>\n",
       "      <td>5.757035e-05</td>\n",
       "      <td>7.196294e-06</td>\n",
       "      <td>1.223370e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.993419e+02</td>\n",
       "      <td>3.630568e+03</td>\n",
       "      <td>5.808043e-02</td>\n",
       "      <td>1.999995e+00</td>\n",
       "      <td>3.452052e+00</td>\n",
       "      <td>6.076382e+03</td>\n",
       "      <td>1.626746e+02</td>\n",
       "      <td>3.156794e-01</td>\n",
       "      <td>5.208455e-02</td>\n",
       "      <td>3.828693e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452184e-01</td>\n",
       "      <td>1.072975e-02</td>\n",
       "      <td>1.105993e-02</td>\n",
       "      <td>2.925108e-02</td>\n",
       "      <td>5.365105e-03</td>\n",
       "      <td>7.461482e-02</td>\n",
       "      <td>1.765018e-01</td>\n",
       "      <td>7.587295e-03</td>\n",
       "      <td>2.682581e-03</td>\n",
       "      <td>1.105993e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.630000e+02</td>\n",
       "      <td>3.010000e+02</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.810000e+02</td>\n",
       "      <td>1.189000e+03</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.590000e+02</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.550000e+02</td>\n",
       "      <td>4.087000e+03</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.498000e+03</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.310000e+02</td>\n",
       "      <td>1.717000e+04</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.940500e+05</td>\n",
       "      <td>1.003020e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Condition          Case      Diameter          Year         Month  \\\n",
       "count  1.167268e+07  1.167268e+07  1.167268e+07  1.167268e+07  1.167268e+07   \n",
       "mean   3.355588e+02  2.809605e+03  5.031340e-01  1.200000e+01  6.499998e+00   \n",
       "std    1.993419e+02  3.630568e+03  5.808043e-02  1.999995e+00  3.452052e+00   \n",
       "min    1.000000e+00  1.000000e+00  5.000000e-01  9.000000e+00  1.000000e+00   \n",
       "25%    1.630000e+02  3.010000e+02  5.000000e-01  1.000000e+01  4.000000e+00   \n",
       "50%    2.810000e+02  1.189000e+03  5.000000e-01  1.200000e+01  6.000000e+00   \n",
       "75%    4.550000e+02  4.087000e+03  5.000000e-01  1.400000e+01  9.000000e+00   \n",
       "max    9.310000e+02  1.717000e+04  1.000000e+01  1.500000e+01  1.200000e+01   \n",
       "\n",
       "          Reference   Consumption      industry       housing   agriculture  \\\n",
       "count  1.167268e+07  1.167268e+07  1.167268e+07  1.167268e+07  1.167268e+07   \n",
       "mean   1.391269e+03  1.757733e+01  1.122546e-01  9.972798e-01  1.468044e-03   \n",
       "std    6.076382e+03  1.626746e+02  3.156794e-01  5.208455e-02  3.828693e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.290000e+02  9.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "50%    5.590000e+02  1.600000e+01  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "75%    1.498000e+03  2.200000e+01  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "max    6.940500e+05  1.003020e+05  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "               ...           Gauge_Otras_Desconocida  Gauge_Precisa_Ii  \\\n",
       "count          ...                      1.167268e+07      1.167268e+07   \n",
       "mean           ...                      2.155290e-02      1.151407e-04   \n",
       "std            ...                      1.452184e-01      1.072975e-02   \n",
       "min            ...                      0.000000e+00      0.000000e+00   \n",
       "25%            ...                      0.000000e+00      0.000000e+00   \n",
       "50%            ...                      0.000000e+00      0.000000e+00   \n",
       "75%            ...                      0.000000e+00      0.000000e+00   \n",
       "max            ...                      1.000000e+00      1.000000e+00   \n",
       "\n",
       "       Gauge_Recordal  Gauge_Sappel  Gauge_Sappel_Aquarius  Gauge_Sensus  \\\n",
       "count    1.167268e+07  1.167268e+07           1.167268e+07  1.167268e+07   \n",
       "mean     1.223370e-04  8.563590e-04           2.878518e-05  5.598717e-03   \n",
       "std      1.105993e-02  2.925108e-02           5.365105e-03  7.461482e-02   \n",
       "min      0.000000e+00  0.000000e+00           0.000000e+00  0.000000e+00   \n",
       "25%      0.000000e+00  0.000000e+00           0.000000e+00  0.000000e+00   \n",
       "50%      0.000000e+00  0.000000e+00           0.000000e+00  0.000000e+00   \n",
       "75%      0.000000e+00  0.000000e+00           0.000000e+00  0.000000e+00   \n",
       "max      1.000000e+00  1.000000e+00           1.000000e+00  1.000000e+00   \n",
       "\n",
       "       Gauge_Shlumberger   Gauge_Tonhy  Gauge_Yt_Md15  Gauge_Zenner_Half_In  \n",
       "count       1.167268e+07  1.167268e+07   1.167268e+07          1.167268e+07  \n",
       "mean        3.218902e-02  5.757035e-05   7.196294e-06          1.223370e-04  \n",
       "std         1.765018e-01  7.587295e-03   2.682581e-03          1.105993e-02  \n",
       "min         0.000000e+00  0.000000e+00   0.000000e+00          0.000000e+00  \n",
       "25%         0.000000e+00  0.000000e+00   0.000000e+00          0.000000e+00  \n",
       "50%         0.000000e+00  0.000000e+00   0.000000e+00          0.000000e+00  \n",
       "75%         0.000000e+00  0.000000e+00   0.000000e+00          0.000000e+00  \n",
       "max         1.000000e+00  1.000000e+00   1.000000e+00          1.000000e+00  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Main questions**\n",
    "- Can we predict the monthly water consumption through the given features?\n",
    "- Can we predict the reference consumtion through the given features?\n",
    "- Is the monthly water consumption affected by the time (month-year)?\n",
    "- What are the most affecting features on the monthly water consumption?\n",
    "- What are the most affecting features on the reference consumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>industry</th>\n",
       "      <th>housing</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>commerce</th>\n",
       "      <th>reserve</th>\n",
       "      <th>...</th>\n",
       "      <th>Gauge_Otras_Desconocida</th>\n",
       "      <th>Gauge_Precisa_Ii</th>\n",
       "      <th>Gauge_Recordal</th>\n",
       "      <th>Gauge_Sappel</th>\n",
       "      <th>Gauge_Sappel_Aquarius</th>\n",
       "      <th>Gauge_Sensus</th>\n",
       "      <th>Gauge_Shlumberger</th>\n",
       "      <th>Gauge_Tonhy</th>\n",
       "      <th>Gauge_Yt_Md15</th>\n",
       "      <th>Gauge_Zenner_Half_In</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3761</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3761</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diameter  Year  Month  Reference  Consumption  industry  housing  \\\n",
       "0       0.5     9      1       3761           17         0        1   \n",
       "1       0.5     9      2       3761           20         0        1   \n",
       "\n",
       "   agriculture  commerce  reserve          ...           \\\n",
       "0            0         1        0          ...            \n",
       "1            0         1        0          ...            \n",
       "\n",
       "   Gauge_Otras_Desconocida  Gauge_Precisa_Ii  Gauge_Recordal  Gauge_Sappel  \\\n",
       "0                        0                 0               0             0   \n",
       "1                        0                 0               0             0   \n",
       "\n",
       "   Gauge_Sappel_Aquarius  Gauge_Sensus  Gauge_Shlumberger  Gauge_Tonhy  \\\n",
       "0                      0             0                  0            0   \n",
       "1                      0             0                  0            0   \n",
       "\n",
       "   Gauge_Yt_Md15  Gauge_Zenner_Half_In  \n",
       "0              0                     0  \n",
       "1              0                     0  \n",
       "\n",
       "[2 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "df.drop(['Condition', 'Case'], axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the independent features\n",
    "data_X = df.drop(['Reference', 'Consumption'], axis=1) \n",
    "\n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the Trainning and testing records for 'Reference' feature\n",
    "X_trainR, X_testR, y_trainR, y_testR = train_test_split(data_X, \n",
    "                                                        data_yR, \n",
    "                                                        test_size=0.33, \n",
    "                                                        random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the Trainning and testing records for 'Consumption' feature\n",
    "X_trainC, X_testC, y_trainC, y_testC = train_test_split(data_X, \n",
    "                                                        data_yC, \n",
    "                                                        test_size=0.33, \n",
    "                                                        random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models\n",
    "modelR = linear_model.LinearRegression()\n",
    "modelC = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the models\n",
    "modelR.fit(X_trainR, y_trainR)\n",
    "modelC.fit(X_trainC, y_trainC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing datasets\n",
    "y_predR = modelR.predict(X_testR)\n",
    "y_predC = modelC.predict(X_testC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the TRAINING datasets\n",
    "y_predR_tr = modelR.predict(X_trainR)\n",
    "y_predC_tr = modelC.predict(X_trainC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "\n",
    "# ... of 'Reference' feature\n",
    "intrcptR = modelR.intercept_\n",
    "coefR = modelR.coef_\n",
    "# for the testing dataset\n",
    "mseR = mean_squared_error(y_testR, y_predR)\n",
    "r2R = r2_score(y_testR, y_predR)\n",
    "# for the training dataset\n",
    "mseR_tr = mean_squared_error(y_trainR, y_predR_tr)\n",
    "r2R_tr = r2_score(y_trainR, y_predR_tr)\n",
    "\n",
    "# ... of 'Consumption' feature\n",
    "intrcptC = modelC.intercept_\n",
    "coefC = modelC.coef_\n",
    "# for the testing dataset\n",
    "mseC = mean_squared_error(y_testC, y_predC)\n",
    "r2C = r2_score(y_testC, y_predC)\n",
    "# for the training dataset\n",
    "mseC_tr = mean_squared_error(y_trainC, y_predC_tr)\n",
    "r2C_tr = r2_score(y_trainC, y_predC_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The metrics for training and testing datasets are:\n",
      "Feature        Dataset      The MSE            the r2\n",
      "==========================================================\n",
      "Reference      Training     34721242.46       06.01%\n",
      "Reference      Testing      34736285.84       05.83%\n",
      "Consumption    Training         6672.03       75.83%\n",
      "Consumption    Testing          6867.61       71.56%\n",
      "==========================================================\n",
      "\n",
      "For the **Reference** feature\n",
      "The fitting coeefficients are:\n",
      "    1- The intercept = -64874898147096.641\n",
      "    2- The slopes    = \n",
      "[ 1.06584295e+04  5.78937534e-01  5.68323124e-02  7.14158468e+02\n",
      "  3.97075552e+03  5.52286459e+03  1.04651857e+03  9.86140430e+02\n",
      "  3.25084202e+03  1.61349906e+03  1.78427096e+03  1.32940154e+03\n",
      "  4.01888821e+13  4.31375301e+13  4.01888821e+13  4.31375301e+13\n",
      " -2.94864803e+12 -2.94864803e+12 -2.94864803e+12 -2.94864803e+12\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860164e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13  2.46860160e+13  2.46860160e+13\n",
      "  2.46860160e+13  2.46860160e+13]\n",
      "and For the **Consumption** feature\n",
      "The fitting coeefficients are:\n",
      "    1- The intercept = 1284515300540.056\n",
      "    2- The slopes    = \n",
      "[ 3.08266541e+02 -3.05495685e-01  6.45531356e-02  4.43831078e+00\n",
      "  9.58474991e+00 -6.83778737e+01 -1.38039060e+02 -1.19025650e+02\n",
      "  1.63639132e+01 -1.31059073e+02 -1.34912716e+02 -1.36104402e+02\n",
      " -9.01678331e+10  5.94428941e+11 -9.01678331e+10  5.94428941e+11\n",
      " -6.84596774e+11 -6.84596774e+11 -6.84596774e+11 -6.84596774e+11\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434742e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434746e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12 -1.19434747e+12 -1.19434747e+12\n",
      " -1.19434747e+12 -1.19434747e+12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''\n",
    "The metrics for training and testing datasets are:\n",
    "Feature        Dataset      The MSE            the r2\n",
    "==========================================================\n",
    "Reference      Training     {mseR_tr:11.2f}       {r2R_tr*100:05.2f}%\n",
    "Reference      Testing      {mseR:11.2f}       {r2R*100:05.2f}%\n",
    "Consumption    Training     {mseC_tr:11.2f}       {r2C_tr*100:05.2f}%\n",
    "Consumption    Testing      {mseC:11.2f}       {r2C*100:05.2f}%\n",
    "==========================================================\n",
    "\n",
    "For the **Reference** feature\n",
    "The fitting coeefficients are:\n",
    "    1- The intercept = {intrcptR:6.3f}\n",
    "    2- The slopes    = \n",
    "{coefR}\n",
    "and For the **Consumption** feature\n",
    "The fitting coeefficients are:\n",
    "    1- The intercept = {intrcptC:6.3f}\n",
    "    2- The slopes    = \n",
    "{coefC}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving th output parameters of the models\n",
    "\n",
    "# Create a saving container\n",
    "\n",
    "models_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving th output parameters of the FIRST model\n",
    "\n",
    "output = (intrcptR, coefR, mseR_tr, r2R_tr, mseR, r2R, \n",
    "            intrcptC, coefC, mseC_tr, r2C_tr, mseC, r2C)\n",
    "models_outputs['Linear with all variables non normalized '] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that the coefficients are equal for the last 53 features, which are the gauges types, hence, all the gauges have the sme effect, or they may have small or no effect on the prediction of either feature.\n",
    "\n",
    "I will repeat the analysis by:\n",
    "1. Removing the gauges\n",
    "2. Normalizing the `Diameter`, `Year`, `Month` features \n",
    "3. Adding a normalized Date feature by combining the `Year` & `Month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fitting_one_model(data_X, data_y, regressor, scale_features=False):\n",
    "    '''\n",
    "    A function to make future fittings easier\n",
    "    inputs:\n",
    "    * data_X, data_y: Arrays for X, Y\n",
    "    * regressor: The regression model, for example:\n",
    "                 linear_model.LinearRegression(normalize=True)\n",
    "\n",
    "    '''\n",
    "    # To measure the time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # specify the Trainning and testing records for 'Reference' feature\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, \n",
    "                                                            data_y, \n",
    "                                                            test_size=0.33, \n",
    "                                                            random_state=79)\n",
    "    if scale_features:\n",
    "        # Apply scaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # fitting on Training data only\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        # transforming\n",
    "        X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "    # define the models\n",
    "    model = regressor # linear_model.LinearRegression()\n",
    "\n",
    "    # Fitting the models\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the TRAINING datasets\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    \n",
    "    # Make predictions using the testing datasets\n",
    "    y_pred = model.predict(X_test)\n",
    "    # The coefficients\n",
    "\n",
    "    # ... of 'Reference' feature\n",
    "    intrcpt = model.intercept_\n",
    "    coef = model.coef_\n",
    "    # for the testing dataset\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # for the training dataset\n",
    "    mse_tr = mean_squared_error(y_train, y_pred_tr)\n",
    "    r2_tr = r2_score(y_train, y_pred_tr)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(elapsed_time)\n",
    "    print(f'The elapsed time for the test is {str(timedelta(seconds=elapsed_time))}')\n",
    "    \n",
    "    return (modelR, (intrcpt, coef, mse_tr, r2_tr, mse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fitting_two_variables(data_X, data_yR, data_yC, regressor):\n",
    "    '''\n",
    "    A function to make future fittings easier\n",
    "    inputs:\n",
    "    * data_X, data_yR, data_yC: Arrays for X, Y1, Y2\n",
    "    * regressor: The regression model, for example:\n",
    "                 linear_model.LinearRegression(normalize=True)\n",
    "\n",
    "    '''\n",
    "    # To measure the time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # specify the Trainning and testing records for 'Reference' feature\n",
    "    X_trainR, X_testR, y_trainR, y_testR = train_test_split(data_X, \n",
    "                                                            data_yR, \n",
    "                                                            test_size=0.33, \n",
    "                                                            random_state=79)\n",
    "    # specify the Trainning and testing records for 'Consumption' feature\n",
    "    X_trainC, X_testC, y_trainC, y_testC = train_test_split(data_X, \n",
    "                                                            data_yC, \n",
    "                                                            test_size=0.33, \n",
    "                                                            random_state=79)\n",
    "    # define the models\n",
    "    modelR = regressor # linear_model.LinearRegression()\n",
    "    modelC = regressor # linear_model.LinearRegression()\n",
    "\n",
    "    # Fitting the models\n",
    "    modelR.fit(X_trainR, y_trainR)\n",
    "    modelC.fit(X_trainC, y_trainC)\n",
    "\n",
    "    # Make predictions using the TRAINING datasets\n",
    "    y_predR_tr = modelR.predict(X_trainR)\n",
    "    y_predC_tr = modelC.predict(X_trainC)\n",
    "\n",
    "    # Make predictions using the testing datasets\n",
    "    y_predR = modelR.predict(X_testR)\n",
    "    y_predC = modelC.predict(X_testC)\n",
    "    # The coefficients\n",
    "\n",
    "    # ... of 'Reference' feature\n",
    "    intrcptR = modelR.intercept_\n",
    "    coefR = modelR.coef_\n",
    "    # for the testing dataset\n",
    "    mseR = mean_squared_error(y_testR, y_predR)\n",
    "    r2R = r2_score(y_testR, y_predR)\n",
    "    # for the training dataset\n",
    "    mseR_tr = mean_squared_error(y_trainR, y_predR_tr)\n",
    "    r2R_tr = r2_score(y_trainR, y_predR_tr)\n",
    "\n",
    "    # ... of 'Consumption' feature\n",
    "    intrcptC = modelC.intercept_\n",
    "    coefC = modelC.coef_\n",
    "    # for the testing dataset\n",
    "    mseC = mean_squared_error(y_testC, y_predC)\n",
    "    r2C = r2_score(y_testC, y_predC)\n",
    "    # for the training dataset\n",
    "    mseC_tr = mean_squared_error(y_trainC, y_predC_tr)\n",
    "    r2C_tr = r2_score(y_trainC, y_predC_tr)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(elapsed_time)\n",
    "    print(f'The elapsed time for the test is {str(timedelta(seconds=elapsed_time))}')\n",
    "    \n",
    "    return ((modelR, modelC), \n",
    "            (intrcptR, coefR, mseR_tr, r2R_tr, mseR, r2R, intrcptC, coefC, mseC_tr, r2C_tr, mseC, r2C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(intrcptR, coefR, mseR_tr, r2R_tr, mseR, r2R, \n",
    "                  intrcptC, coefC, mseC_tr, r2C_tr, mseC, r2C):\n",
    "    print(f'''\n",
    "    The metrics for training and testing datasets are:\n",
    "    Feature        Dataset      The MSE            the r2\n",
    "    ==========================================================\n",
    "    Reference      Training     {mseR_tr:11.2f}       {r2R_tr*100:05.2f}%\n",
    "    Reference      Testing      {mseR:11.2f}       {r2R*100:05.2f}%\n",
    "    Consumption    Training     {mseC_tr:11.2f}       {r2C_tr*100:05.2f}%\n",
    "    Consumption    Testing      {mseC:11.2f}       {r2C*100:05.2f}%\n",
    "    ==========================================================\n",
    "\n",
    "    For the **Reference** feature\n",
    "    The fitting coeefficients are:\n",
    "        1- The intercept = {intrcptR}\n",
    "        2- The slopes    = \n",
    "    {coefR}\n",
    "    and For the **Consumption** feature\n",
    "    The fitting coeefficients are:\n",
    "        1- The intercept = {intrcptC}\n",
    "        2- The slopes    = \n",
    "    {coefC}\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.41742467880249\n",
      "The elapsed time for the test is 0:00:10.417425\n",
      "10.63883900642395\n",
      "The elapsed time for the test is 0:00:10.638839\n",
      "\n",
      "    The metrics for training and testing datasets are:\n",
      "    Feature        Dataset      The MSE            the r2\n",
      "    ==========================================================\n",
      "    Reference      Training     36191634.27       02.02%\n",
      "    Reference      Testing      36175800.03       01.93%\n",
      "    Consumption    Training        20688.02       25.06%\n",
      "    Consumption    Testing         18840.00       21.97%\n",
      "    ==========================================================\n",
      "\n",
      "    For the **Reference** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = 28862222325123.113\n",
      "        2- The slopes    = \n",
      "    [ 1.17349426e+04  9.46150480e+02  7.88293510e+01  6.29363615e+02\n",
      "  5.00882389e+03  8.17339927e+03  2.97325523e+03  1.98265450e+03\n",
      "  5.50506795e+03  3.54109150e+03  3.61524336e+03  3.01788609e+03\n",
      " -2.88622223e+13  3.94432581e+12 -2.88622223e+13  3.94432581e+12\n",
      " -3.28065482e+13 -3.28065482e+13 -3.28065482e+13 -3.28065482e+13\n",
      " -2.58952550e+00]\n",
      "    and For the **Consumption** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = 1525699085810.638\n",
      "        2- The slopes    = \n",
      "    [ 1.44031795e+03  3.55339931e+01  3.06404930e+00  4.55372493e+00\n",
      " -2.63172772e+01  1.59088565e+02  2.91992877e+02  2.68715883e+02\n",
      " -8.93407546e+01  2.95981545e+02  2.94118358e+02  2.98323215e+02\n",
      " -1.52569909e+12 -2.14011093e+11 -1.52569909e+12 -2.14011093e+11\n",
      " -1.31168799e+12 -1.31168799e+12 -1.31168799e+12 -1.31168799e+12\n",
      " -9.81730421e-02]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Second trial\n",
    "# Refitting using the new set of features by \n",
    "# Normalizing all X values and Removing the Gauge Features\n",
    "\n",
    "# Select X features, with Removing the Gauge Features\n",
    "data_X = df[[x for x in list(df) if x[:5]!='Gauge']].drop(['Reference', 'Consumption'], axis=1)\n",
    "# create a Date_delta column, as integer, to allow regression\n",
    "# as regression could not be fit on DateTime series\n",
    "\n",
    "# Assigning Date column\n",
    "data_X.assign(CurrentDate=0,)\n",
    "data_X['CurrentDate'] = pd.to_datetime(dict(year=data_X.Year+2000, month=data_X.Month, day=15))\n",
    "# Creating an integer date value\n",
    "data_X.assign(date_delta=0)\n",
    "data_X['date_delta'] = (data_X['CurrentDate'] - data_X['CurrentDate'].min())  / np.timedelta64(1,'D')\n",
    "# Dropping the initial column\n",
    "data_X.drop(['CurrentDate'], axis=1, inplace=True)\n",
    "\n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']\n",
    "\n",
    "# Apply the model\n",
    "output_R = perform_fitting_one_model(data_X, data_yR, \n",
    "                         linear_model.LinearRegression(normalize=True))\n",
    "coefficients = list(output_R[1])\n",
    "output_C = perform_fitting_one_model(data_X, data_yC, \n",
    "                         linear_model.LinearRegression(normalize=True))\n",
    "coefficients += list(output_C[1])\n",
    "# Saving th output parameters of the SECOND model\n",
    "models_outputs['Linear with non-Gauge variables normalized'] = coefficients\n",
    "# Printing results\n",
    "print_results(*coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 14550.70, NNZs: 74, Bias: -1448.151007, T: 7820692, Avg. loss: 18262591.493152\n",
      "Total training time: 3.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16554.76, NNZs: 74, Bias: -2186.877487, T: 15641384, Avg. loss: 18071260.844813\n",
      "Total training time: 6.62 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18442.62, NNZs: 74, Bias: -2604.683239, T: 23462076, Avg. loss: 18021923.300272\n",
      "Total training time: 9.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 19379.74, NNZs: 74, Bias: -2840.784034, T: 31282768, Avg. loss: 17992153.489570\n",
      "Total training time: 12.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 20092.70, NNZs: 74, Bias: -2901.002269, T: 39103460, Avg. loss: 17973631.177351\n",
      "Total training time: 15.59 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20826.31, NNZs: 74, Bias: -3032.795823, T: 46924152, Avg. loss: 17958061.683938\n",
      "Total training time: 18.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21926.80, NNZs: 74, Bias: -3102.863077, T: 54744844, Avg. loss: 17946157.631850\n",
      "Total training time: 21.46 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21962.90, NNZs: 74, Bias: -3370.208388, T: 62565536, Avg. loss: 17935158.000308\n",
      "Total training time: 24.41 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 22315.57, NNZs: 74, Bias: -3249.633505, T: 70386228, Avg. loss: 17925601.246714\n",
      "Total training time: 27.38 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 23119.84, NNZs: 74, Bias: -3302.886979, T: 78206920, Avg. loss: 17919924.597770\n",
      "Total training time: 30.33 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 23411.11, NNZs: 74, Bias: -3388.436847, T: 86027612, Avg. loss: 17913522.441352\n",
      "Total training time: 33.26 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 23777.94, NNZs: 74, Bias: -3354.548230, T: 93848304, Avg. loss: 17906880.962889\n",
      "Total training time: 36.20 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 24073.83, NNZs: 74, Bias: -3410.604239, T: 101668996, Avg. loss: 17901918.205392\n",
      "Total training time: 39.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 24269.61, NNZs: 74, Bias: -3496.650853, T: 109489688, Avg. loss: 17897424.743090\n",
      "Total training time: 42.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 24770.12, NNZs: 74, Bias: -3443.792930, T: 117310380, Avg. loss: 17893492.949331\n",
      "Total training time: 45.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 25020.58, NNZs: 74, Bias: -3582.790167, T: 125131072, Avg. loss: 17890273.197008\n",
      "Total training time: 48.09 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 25005.59, NNZs: 74, Bias: -3519.648347, T: 132951764, Avg. loss: 17883694.326106\n",
      "Total training time: 51.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 25245.80, NNZs: 74, Bias: -3583.041401, T: 140772456, Avg. loss: 17881847.758794\n",
      "Total training time: 54.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 25497.77, NNZs: 74, Bias: -3633.380856, T: 148593148, Avg. loss: 17880403.950316\n",
      "Total training time: 57.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 25790.04, NNZs: 74, Bias: -3634.611930, T: 156413840, Avg. loss: 17877653.153998\n",
      "Total training time: 60.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 25869.69, NNZs: 74, Bias: -3651.720907, T: 164234532, Avg. loss: 17872989.029656\n",
      "Total training time: 62.96 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 25796.82, NNZs: 74, Bias: -3674.324009, T: 172055224, Avg. loss: 17870618.340558\n",
      "Total training time: 66.13 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 25962.15, NNZs: 74, Bias: -3728.957145, T: 179875916, Avg. loss: 17868583.383165\n",
      "Total training time: 69.20 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 26436.50, NNZs: 74, Bias: -3718.845897, T: 187696608, Avg. loss: 17867363.789697\n",
      "Total training time: 72.13 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 26452.24, NNZs: 74, Bias: -3787.641852, T: 195517300, Avg. loss: 17864991.115181\n",
      "Total training time: 75.09 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 26472.36, NNZs: 74, Bias: -3826.942446, T: 203337992, Avg. loss: 17862451.103618\n",
      "Total training time: 78.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 26763.04, NNZs: 74, Bias: -3791.246613, T: 211158684, Avg. loss: 17860890.785700\n",
      "Total training time: 80.94 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 26697.49, NNZs: 74, Bias: -3804.399755, T: 218979376, Avg. loss: 17858852.680289\n",
      "Total training time: 83.90 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 26604.08, NNZs: 74, Bias: -3776.654927, T: 226800068, Avg. loss: 17856604.493440\n",
      "Total training time: 86.87 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 26875.53, NNZs: 74, Bias: -3779.185030, T: 234620760, Avg. loss: 17855546.187528\n",
      "Total training time: 89.83 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 27063.69, NNZs: 74, Bias: -3858.917773, T: 242441452, Avg. loss: 17852993.708489\n",
      "Total training time: 92.82 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 27056.01, NNZs: 74, Bias: -3922.939319, T: 250262144, Avg. loss: 17853362.009507\n",
      "Total training time: 95.85 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27164.89, NNZs: 74, Bias: -3900.970659, T: 258082836, Avg. loss: 17851189.681603\n",
      "Total training time: 98.80 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 27116.65, NNZs: 74, Bias: -3885.016133, T: 265903528, Avg. loss: 17849821.386603\n",
      "Total training time: 101.73 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 27215.49, NNZs: 74, Bias: -3897.990051, T: 273724220, Avg. loss: 17849114.047003\n",
      "Total training time: 104.66 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 27148.44, NNZs: 74, Bias: -3947.314117, T: 281544912, Avg. loss: 17847312.004030\n",
      "Total training time: 107.62 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 27606.82, NNZs: 74, Bias: -3870.510149, T: 289365604, Avg. loss: 17846186.866213\n",
      "Total training time: 110.60 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 27451.00, NNZs: 74, Bias: -3986.752487, T: 297186296, Avg. loss: 17846174.338941\n",
      "Total training time: 113.63 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 27472.88, NNZs: 74, Bias: -3936.360098, T: 305006988, Avg. loss: 17844814.889394\n",
      "Total training time: 116.81 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 27339.27, NNZs: 74, Bias: -3962.549512, T: 312827680, Avg. loss: 17842934.313646\n",
      "Total training time: 119.85 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 27594.10, NNZs: 74, Bias: -3931.645491, T: 320648372, Avg. loss: 17843088.961695\n",
      "Total training time: 122.91 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 27515.21, NNZs: 74, Bias: -3954.605437, T: 328469064, Avg. loss: 17841216.899464\n",
      "Total training time: 125.88 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 27620.20, NNZs: 74, Bias: -3941.313178, T: 336289756, Avg. loss: 17839987.824239\n",
      "Total training time: 128.88 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 27645.62, NNZs: 74, Bias: -3938.839366, T: 344110448, Avg. loss: 17840215.086006\n",
      "Total training time: 131.80 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 27707.64, NNZs: 74, Bias: -3998.298941, T: 351931140, Avg. loss: 17838333.591473\n",
      "Total training time: 134.73 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 27596.68, NNZs: 74, Bias: -3965.073033, T: 359751832, Avg. loss: 17836799.346631\n",
      "Total training time: 137.68 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 27681.69, NNZs: 74, Bias: -3995.527870, T: 367572524, Avg. loss: 17837028.868662\n",
      "Total training time: 140.63 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 27630.55, NNZs: 74, Bias: -4061.442920, T: 375393216, Avg. loss: 17836563.927963\n",
      "Total training time: 143.59 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 27595.52, NNZs: 74, Bias: -3997.550662, T: 383213908, Avg. loss: 17834334.506224\n",
      "Total training time: 146.52 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 27714.99, NNZs: 74, Bias: -4020.852351, T: 391034600, Avg. loss: 17834171.783888\n",
      "Total training time: 149.45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.91932010650635\n",
      "The elapsed time for the test is 0:02:57.919320\n",
      "-- Epoch 1\n",
      "Norm: 1587.11, NNZs: 74, Bias: -383.333766, T: 7820692, Avg. loss: 10839.075678\n",
      "Total training time: 2.98 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1765.74, NNZs: 74, Bias: -449.396532, T: 15641384, Avg. loss: 10337.936148\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1750.98, NNZs: 74, Bias: -435.029242, T: 23462076, Avg. loss: 10164.925742\n",
      "Total training time: 8.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2051.15, NNZs: 74, Bias: -482.187936, T: 31282768, Avg. loss: 10122.908610\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2033.29, NNZs: 74, Bias: -476.677075, T: 39103460, Avg. loss: 10045.723780\n",
      "Total training time: 15.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2184.45, NNZs: 74, Bias: -495.243969, T: 46924152, Avg. loss: 10027.009646\n",
      "Total training time: 18.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2358.96, NNZs: 74, Bias: -508.339833, T: 54744844, Avg. loss: 9946.243822\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2347.63, NNZs: 74, Bias: -501.202150, T: 62565536, Avg. loss: 9937.948233\n",
      "Total training time: 24.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2326.49, NNZs: 74, Bias: -507.690543, T: 70386228, Avg. loss: 9897.507865\n",
      "Total training time: 26.99 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2357.34, NNZs: 74, Bias: -504.722898, T: 78206920, Avg. loss: 9863.294918\n",
      "Total training time: 29.94 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2487.15, NNZs: 74, Bias: -506.955689, T: 86027612, Avg. loss: 9871.371434\n",
      "Total training time: 32.90 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2551.43, NNZs: 74, Bias: -524.062413, T: 93848304, Avg. loss: 9835.400075\n",
      "Total training time: 35.89 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2556.23, NNZs: 74, Bias: -516.948692, T: 101668996, Avg. loss: 9809.568244\n",
      "Total training time: 38.87 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2611.89, NNZs: 74, Bias: -522.502231, T: 109489688, Avg. loss: 9798.438973\n",
      "Total training time: 41.86 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2717.41, NNZs: 74, Bias: -531.682451, T: 117310380, Avg. loss: 9783.100020\n",
      "Total training time: 44.83 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2718.70, NNZs: 74, Bias: -541.767497, T: 125131072, Avg. loss: 9770.403693\n",
      "Total training time: 47.79 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2707.24, NNZs: 74, Bias: -535.774622, T: 132951764, Avg. loss: 9733.033261\n",
      "Total training time: 50.77 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2729.97, NNZs: 74, Bias: -536.373228, T: 140772456, Avg. loss: 9734.836188\n",
      "Total training time: 53.81 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 2807.59, NNZs: 74, Bias: -542.455621, T: 148593148, Avg. loss: 9739.517658\n",
      "Total training time: 56.86 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 2840.46, NNZs: 74, Bias: -554.835761, T: 156413840, Avg. loss: 9713.474175\n",
      "Total training time: 59.91 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 2791.62, NNZs: 74, Bias: -543.719678, T: 164234532, Avg. loss: 9685.587025\n",
      "Total training time: 62.93 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2832.79, NNZs: 74, Bias: -537.639288, T: 172055224, Avg. loss: 9697.548101\n",
      "Total training time: 65.99 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2888.64, NNZs: 74, Bias: -545.192111, T: 179875916, Avg. loss: 9696.148939\n",
      "Total training time: 69.09 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2882.50, NNZs: 74, Bias: -555.490990, T: 187696608, Avg. loss: 9678.577977\n",
      "Total training time: 72.17 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2896.20, NNZs: 74, Bias: -548.813493, T: 195517300, Avg. loss: 9677.718343\n",
      "Total training time: 75.30 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2957.13, NNZs: 74, Bias: -552.734135, T: 203337992, Avg. loss: 9677.201648\n",
      "Total training time: 78.24 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2958.78, NNZs: 74, Bias: -564.638038, T: 211158684, Avg. loss: 9665.621834\n",
      "Total training time: 81.18 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2919.90, NNZs: 74, Bias: -561.832631, T: 218979376, Avg. loss: 9650.893501\n",
      "Total training time: 84.10 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2949.47, NNZs: 74, Bias: -559.107740, T: 226800068, Avg. loss: 9664.339214\n",
      "Total training time: 87.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2983.01, NNZs: 74, Bias: -564.464834, T: 234620760, Avg. loss: 9654.789474\n",
      "Total training time: 89.97 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2954.96, NNZs: 74, Bias: -567.136745, T: 242441452, Avg. loss: 9639.205384\n",
      "Total training time: 92.89 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2959.49, NNZs: 74, Bias: -558.926713, T: 250262144, Avg. loss: 9639.043683\n",
      "Total training time: 95.85 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2978.72, NNZs: 74, Bias: -560.598691, T: 258082836, Avg. loss: 9641.963582\n",
      "Total training time: 98.78 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2983.70, NNZs: 74, Bias: -564.083897, T: 265903528, Avg. loss: 9638.422935\n",
      "Total training time: 101.72 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3007.64, NNZs: 74, Bias: -565.086770, T: 273724220, Avg. loss: 9640.649871\n",
      "Total training time: 104.65 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3046.86, NNZs: 74, Bias: -573.430154, T: 281544912, Avg. loss: 9632.819503\n",
      "Total training time: 107.59 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3025.04, NNZs: 74, Bias: -573.069067, T: 289365604, Avg. loss: 9624.151065\n",
      "Total training time: 110.54 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3024.21, NNZs: 74, Bias: -568.349064, T: 297186296, Avg. loss: 9625.513345\n",
      "Total training time: 113.66 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3046.42, NNZs: 74, Bias: -569.488397, T: 305006988, Avg. loss: 9623.698111\n",
      "Total training time: 116.84 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3060.24, NNZs: 74, Bias: -581.444509, T: 312827680, Avg. loss: 9611.984095\n",
      "Total training time: 119.98 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3034.83, NNZs: 74, Bias: -576.501469, T: 320648372, Avg. loss: 9608.931394\n",
      "Total training time: 123.04 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3032.77, NNZs: 74, Bias: -568.677604, T: 328469064, Avg. loss: 9609.768961\n",
      "Total training time: 126.05 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3034.95, NNZs: 74, Bias: -573.370568, T: 336289756, Avg. loss: 9614.232012\n",
      "Total training time: 129.05 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3073.24, NNZs: 74, Bias: -573.794876, T: 344110448, Avg. loss: 9617.438928\n",
      "Total training time: 132.11 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3038.37, NNZs: 74, Bias: -577.774840, T: 351931140, Avg. loss: 9595.851851\n",
      "Total training time: 135.15 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3038.85, NNZs: 74, Bias: -573.916133, T: 359751832, Avg. loss: 9607.370024\n",
      "Total training time: 138.12 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3054.07, NNZs: 74, Bias: -563.869345, T: 367572524, Avg. loss: 9608.333600\n",
      "Total training time: 141.05 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3080.99, NNZs: 74, Bias: -577.832984, T: 375393216, Avg. loss: 9606.268736\n",
      "Total training time: 143.99 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3057.04, NNZs: 74, Bias: -579.034869, T: 383213908, Avg. loss: 9596.399250\n",
      "Total training time: 146.93 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3079.06, NNZs: 74, Bias: -577.788356, T: 391034600, Avg. loss: 9608.400224\n",
      "Total training time: 149.85 seconds.\n",
      "Convergence after 50 epochs took 149.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.4099497795105\n",
      "The elapsed time for the test is 0:02:52.409950\n",
      "\n",
      "    The metrics for training and testing datasets are:\n",
      "    Feature        Dataset      The MSE            the r2\n",
      "    ==========================================================\n",
      "    Reference      Training     35455202.34       04.02%\n",
      "    Reference      Testing      35445711.47       03.91%\n",
      "    Consumption    Training        18982.31       31.24%\n",
      "    Consumption    Testing         17383.11       28.00%\n",
      "    ==========================================================\n",
      "\n",
      "    For the **Reference** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-4020.85235125]\n",
      "        2- The slopes    = \n",
      "    [ 1.15755898e+04 -6.74443862e+00 -1.47230964e+01  5.08430899e+02\n",
      "  3.36946877e+03  3.85339778e+03 -6.22481878e+02 -1.07628527e+03\n",
      "  3.90843405e+03 -2.11309707e+02 -2.94028616e+01 -4.83855475e+02\n",
      "  5.84309093e+03 -1.53202680e+03 -2.87636572e+03 -1.73178769e+03\n",
      " -1.35398262e+03 -1.04712966e+03  5.00605887e+02 -1.36330810e+03\n",
      "  3.54070200e+02  1.35226531e+02 -6.39340410e+03 -1.67006168e+03\n",
      " -2.10602870e+02 -6.60214827e+02 -4.90180195e+02 -6.48907842e+01\n",
      " -9.12683210e+01 -3.57374146e+02  3.52200463e+02 -1.02791549e+02\n",
      "  4.10273769e+02  8.96330309e+02  1.31628610e+02 -1.07253560e+03\n",
      " -7.76982506e+02 -2.03065281e+03  4.02035610e+01 -2.52197744e+02\n",
      " -1.76534239e+02  2.06874120e+02 -4.34048096e+02 -2.28912821e+02\n",
      " -1.73926014e+02 -2.84878260e+02 -2.99795831e+01 -1.28827066e+03\n",
      "  6.17620256e+01 -3.93182756e+03 -8.71440419e+02 -7.46506995e+02\n",
      "  4.70643122e+02  1.10091933e+01  2.27042153e+02  1.22934701e+02\n",
      "  8.65502267e+02 -2.45464899e+02  3.14889015e+02  2.13527950e+04\n",
      " -1.40854003e+02 -1.17596336e+03 -4.08457095e+01 -2.29049117e+03\n",
      "  6.52468305e+02  1.13307792e+02  7.50822020e+02 -3.41340320e+02\n",
      "  1.04319559e+01  6.60794432e+02  8.85207792e+01 -7.84431845e+02\n",
      " -7.83117135e+01 -1.08963477e+03]\n",
      "    and For the **Consumption** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-577.78835603]\n",
      "        2- The slopes    = \n",
      "    [ 1.39213375e+03 -3.17517393e-01 -2.33825013e-01  9.04463104e+00\n",
      " -4.07489424e+01 -6.98958196e+01  2.54546961e+01  1.64760871e+01\n",
      " -8.09866349e+01  3.71590803e+01  3.33835311e+01  3.64806654e+01\n",
      "  6.93020518e+01 -2.13204916e+01 -4.23911030e+01 -3.55862567e+01\n",
      " -1.78182032e+01 -2.32613908e+01  1.35317651e+01 -2.93589193e+01\n",
      " -7.32494504e+01 -4.57606353e+01 -3.76635803e+02 -3.17522295e+01\n",
      " -2.52985164e+01 -4.26270355e+01 -9.00245921e+00 -5.26333267e+01\n",
      " -9.03513449e+00 -3.76035513e+01 -2.74194867e+01 -3.15095307e+00\n",
      " -4.94219924e+01 -2.17236796e+02 -5.20229717e+01 -4.80726394e+01\n",
      " -5.25695514e+01 -2.29302939e+02 -6.16540446e+00 -4.64085585e+01\n",
      " -2.66603375e+01 -2.06250900e+00 -5.68582352e+01 -5.89201261e+00\n",
      " -1.08589934e+02 -2.32084881e+01 -2.90609840e+00 -5.47222152e+01\n",
      " -5.51248988e+01  2.67456512e+03 -1.63916279e+01 -3.52281798e+01\n",
      " -2.18476009e+01 -5.06835910e+00 -4.34050610e+01 -4.74059598e+01\n",
      " -6.11212258e+01 -5.81440180e+00 -7.56536361e+00 -6.99043989e+01\n",
      " -2.57231446e+00 -4.82068623e+01 -7.16445330e+00 -4.82358832e+01\n",
      " -4.88486057e+01 -2.86159428e+01 -2.51453428e+01 -1.70320157e+02\n",
      " -3.36827440e+01 -1.07983904e+02 -4.68643194e+01 -1.53566244e+01\n",
      " -3.98060176e+00 -3.24368225e+01]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Trying to fit with another regressor\n",
    "# Trying the Stochastic Gradient Descent Regressor\n",
    "\n",
    "# Separate the independent features\n",
    "data_X = df.drop(['Reference', 'Consumption'], axis=1) \n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']\n",
    "\n",
    "# Apply the model\n",
    "output_R = perform_fitting_one_model(data_X, data_yR, \n",
    "                         linear_model.SGDRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=2), \n",
    "                                     scale_features=False)\n",
    "coefficients = list(output_R[1])\n",
    "output_C = perform_fitting_one_model(data_X, data_yC, \n",
    "                         linear_model.SGDRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=2), \n",
    "                                     scale_features=False)\n",
    "coefficients += list(output_C[1])    \n",
    "# Saving th output parameters of the SECOND model\n",
    "\n",
    "models_outputs['SGDRegressor over all data unnormalized'] =coefficients\n",
    "# Printing results\n",
    "print_results(*coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 13693.23, NNZs: 20, Bias: -2134.510292, T: 7820692, Avg. loss: 18616858.269417\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14565.12, NNZs: 20, Bias: -2948.407333, T: 15641384, Avg. loss: 18435848.133573\n",
      "Total training time: 3.99 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14147.92, NNZs: 20, Bias: -3322.815629, T: 23462076, Avg. loss: 18390805.516840\n",
      "Total training time: 6.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14866.38, NNZs: 20, Bias: -3631.876183, T: 31282768, Avg. loss: 18364835.348611\n",
      "Total training time: 8.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14464.87, NNZs: 20, Bias: -3738.106784, T: 39103460, Avg. loss: 18346963.110266\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14876.35, NNZs: 20, Bias: -3794.042452, T: 46924152, Avg. loss: 18334226.687918\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 14901.46, NNZs: 20, Bias: -3968.031668, T: 54744844, Avg. loss: 18324686.783425\n",
      "Total training time: 14.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 15384.36, NNZs: 20, Bias: -4103.758369, T: 62565536, Avg. loss: 18316422.898867\n",
      "Total training time: 16.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15675.22, NNZs: 20, Bias: -4168.470061, T: 70386228, Avg. loss: 18310954.867198\n",
      "Total training time: 18.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 15501.33, NNZs: 20, Bias: -4291.239781, T: 78206920, Avg. loss: 18303486.330676\n",
      "Total training time: 20.22 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 15680.20, NNZs: 20, Bias: -4338.895631, T: 86027612, Avg. loss: 18299198.488670\n",
      "Total training time: 22.34 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 14905.01, NNZs: 20, Bias: -4445.724342, T: 93848304, Avg. loss: 18293681.784048\n",
      "Total training time: 24.36 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 15372.51, NNZs: 20, Bias: -4494.241268, T: 101668996, Avg. loss: 18290876.191031\n",
      "Total training time: 26.48 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 15136.35, NNZs: 20, Bias: -4476.333790, T: 109489688, Avg. loss: 18284700.269147\n",
      "Total training time: 28.57 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 15423.79, NNZs: 20, Bias: -4531.212104, T: 117310380, Avg. loss: 18283612.319811\n",
      "Total training time: 30.55 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 15479.25, NNZs: 20, Bias: -4630.480844, T: 125131072, Avg. loss: 18279424.404373\n",
      "Total training time: 32.58 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 15289.12, NNZs: 20, Bias: -4648.528375, T: 132951764, Avg. loss: 18277436.218949\n",
      "Total training time: 34.65 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 15405.17, NNZs: 20, Bias: -4655.251503, T: 140772456, Avg. loss: 18274954.664842\n",
      "Total training time: 36.79 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 15241.44, NNZs: 20, Bias: -4625.455633, T: 148593148, Avg. loss: 18271617.720591\n",
      "Total training time: 38.92 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 14844.61, NNZs: 20, Bias: -4697.706228, T: 156413840, Avg. loss: 18269189.922816\n",
      "Total training time: 41.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 15207.06, NNZs: 20, Bias: -4771.686757, T: 164234532, Avg. loss: 18267921.455622\n",
      "Total training time: 43.13 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 15363.21, NNZs: 20, Bias: -4792.733991, T: 172055224, Avg. loss: 18265766.068283\n",
      "Total training time: 45.23 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 15066.94, NNZs: 20, Bias: -4801.511276, T: 179875916, Avg. loss: 18261372.447958\n",
      "Total training time: 47.24 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 15431.74, NNZs: 20, Bias: -4873.830640, T: 187696608, Avg. loss: 18261770.997858\n",
      "Total training time: 49.21 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 15155.39, NNZs: 20, Bias: -4901.294784, T: 195517300, Avg. loss: 18260600.375672\n",
      "Total training time: 51.19 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 15145.20, NNZs: 20, Bias: -4973.017049, T: 203337992, Avg. loss: 18256885.604435\n",
      "Total training time: 53.22 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 15400.66, NNZs: 20, Bias: -4942.429498, T: 211158684, Avg. loss: 18256382.202106\n",
      "Total training time: 55.15 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 15474.00, NNZs: 20, Bias: -4974.819028, T: 218979376, Avg. loss: 18255662.100387\n",
      "Total training time: 57.18 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 15122.73, NNZs: 20, Bias: -4997.600228, T: 226800068, Avg. loss: 18254042.849937\n",
      "Total training time: 59.21 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 15058.11, NNZs: 20, Bias: -4984.910450, T: 234620760, Avg. loss: 18251813.938056\n",
      "Total training time: 61.22 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 15224.19, NNZs: 20, Bias: -4932.665490, T: 242441452, Avg. loss: 18250953.018653\n",
      "Total training time: 63.21 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 15402.88, NNZs: 20, Bias: -5014.152493, T: 250262144, Avg. loss: 18250125.699438\n",
      "Total training time: 65.23 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 15039.65, NNZs: 20, Bias: -5000.770265, T: 258082836, Avg. loss: 18248523.036114\n",
      "Total training time: 67.28 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 15345.67, NNZs: 20, Bias: -4963.998324, T: 265903528, Avg. loss: 18248095.718078\n",
      "Total training time: 69.32 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 15183.56, NNZs: 20, Bias: -4989.288496, T: 273724220, Avg. loss: 18247307.354973\n",
      "Total training time: 71.39 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15366.09, NNZs: 20, Bias: -5012.238419, T: 281544912, Avg. loss: 18246466.763144\n",
      "Total training time: 73.43 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 15376.72, NNZs: 20, Bias: -5052.672260, T: 289365604, Avg. loss: 18243412.039779\n",
      "Total training time: 75.44 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 15575.88, NNZs: 20, Bias: -5113.901485, T: 297186296, Avg. loss: 18243330.467403\n",
      "Total training time: 77.47 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 15320.04, NNZs: 20, Bias: -5145.765169, T: 305006988, Avg. loss: 18241613.578775\n",
      "Total training time: 79.45 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15077.00, NNZs: 20, Bias: -5138.653157, T: 312827680, Avg. loss: 18241543.505083\n",
      "Total training time: 81.44 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 15185.99, NNZs: 20, Bias: -5125.302643, T: 320648372, Avg. loss: 18239722.878254\n",
      "Total training time: 83.50 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 15244.52, NNZs: 20, Bias: -5127.670360, T: 328469064, Avg. loss: 18239265.887624\n",
      "Total training time: 85.62 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 15104.76, NNZs: 20, Bias: -5161.057978, T: 336289756, Avg. loss: 18238953.974870\n",
      "Total training time: 87.78 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 15255.56, NNZs: 20, Bias: -5175.406232, T: 344110448, Avg. loss: 18236566.496740\n",
      "Total training time: 89.89 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 15150.82, NNZs: 20, Bias: -5185.662442, T: 351931140, Avg. loss: 18237614.433801\n",
      "Total training time: 92.08 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 14905.49, NNZs: 20, Bias: -5177.888436, T: 359751832, Avg. loss: 18236545.480497\n",
      "Total training time: 94.21 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 14799.32, NNZs: 20, Bias: -5141.711035, T: 367572524, Avg. loss: 18235489.390978\n",
      "Total training time: 96.30 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 14976.75, NNZs: 20, Bias: -5199.882161, T: 375393216, Avg. loss: 18234484.122290\n",
      "Total training time: 98.47 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 15339.06, NNZs: 20, Bias: -5195.200214, T: 383213908, Avg. loss: 18233478.748924\n",
      "Total training time: 100.55 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 15334.02, NNZs: 20, Bias: -5177.293044, T: 391034600, Avg. loss: 18233855.673510\n",
      "Total training time: 102.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.64909553527832\n",
      "The elapsed time for the test is 0:01:49.649096\n",
      "-- Epoch 1\n",
      "Norm: 1355.68, NNZs: 20, Bias: -399.155643, T: 7820692, Avg. loss: 10974.866409\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1489.77, NNZs: 20, Bias: -471.709066, T: 15641384, Avg. loss: 10603.170831\n",
      "Total training time: 3.86 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1304.06, NNZs: 20, Bias: -468.988586, T: 23462076, Avg. loss: 10582.733624\n",
      "Total training time: 5.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1455.22, NNZs: 20, Bias: -500.690873, T: 31282768, Avg. loss: 10577.823253\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1340.79, NNZs: 20, Bias: -506.643461, T: 39103460, Avg. loss: 10557.148682\n",
      "Total training time: 9.72 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1371.95, NNZs: 20, Bias: -520.409202, T: 46924152, Avg. loss: 10534.119277\n",
      "Total training time: 11.69 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1403.72, NNZs: 20, Bias: -536.716668, T: 54744844, Avg. loss: 10557.420813\n",
      "Total training time: 13.64 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1335.03, NNZs: 20, Bias: -540.308143, T: 62565536, Avg. loss: 10532.540945\n",
      "Total training time: 15.59 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1380.95, NNZs: 20, Bias: -542.201714, T: 70386228, Avg. loss: 10543.302543\n",
      "Total training time: 17.54 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1316.53, NNZs: 20, Bias: -543.062513, T: 78206920, Avg. loss: 10511.656943\n",
      "Total training time: 19.48 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1392.70, NNZs: 20, Bias: -562.501877, T: 86027612, Avg. loss: 10531.388035\n",
      "Total training time: 21.53 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1427.44, NNZs: 20, Bias: -570.241113, T: 93848304, Avg. loss: 10524.970394\n",
      "Total training time: 23.53 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1275.32, NNZs: 20, Bias: -557.024576, T: 101668996, Avg. loss: 10465.672875\n",
      "Total training time: 25.44 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1299.96, NNZs: 20, Bias: -572.907738, T: 109489688, Avg. loss: 10522.660928\n",
      "Total training time: 27.36 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1405.33, NNZs: 20, Bias: -578.832797, T: 117310380, Avg. loss: 10525.925851\n",
      "Total training time: 29.27 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1521.12, NNZs: 20, Bias: -602.722432, T: 125131072, Avg. loss: 10490.467056\n",
      "Total training time: 31.23 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1541.39, NNZs: 20, Bias: -604.969413, T: 132951764, Avg. loss: 10506.216430\n",
      "Total training time: 33.17 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1467.14, NNZs: 20, Bias: -613.062718, T: 140772456, Avg. loss: 10479.006815\n",
      "Total training time: 35.12 seconds.\n",
      "Convergence after 18 epochs took 35.12 seconds\n",
      "41.91841244697571\n",
      "The elapsed time for the test is 0:00:41.918412\n",
      "\n",
      "    The metrics for training and testing datasets are:\n",
      "    Feature        Dataset      The MSE            the r2\n",
      "    ==========================================================\n",
      "    Reference      Training     43797050.94       -18.56%\n",
      "    Reference      Testing      43773973.05       -18.67%\n",
      "    Consumption    Training        20739.55       24.87%\n",
      "    Consumption    Testing         18903.53       21.71%\n",
      "    ==========================================================\n",
      "\n",
      "    For the **Reference** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-5177.29304409]\n",
      "        2- The slopes    = \n",
      "    [ 1.14396344e+04  1.82943292e+02  6.46953421e+01  4.40383537e+02\n",
      "  3.72397981e+03  3.87304747e+03 -4.01925371e+02 -1.46440200e+03\n",
      "  4.29017787e+03 -9.20646134e+00  5.58598543e+01 -5.49403932e+02\n",
      "  5.85211093e+03 -1.46929379e+03 -2.77399335e+03 -1.95058132e+03\n",
      " -1.57564378e+03 -9.96696708e+02  6.73735995e+02 -1.52127062e+03]\n",
      "    and For the **Consumption** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-613.06271815]\n",
      "        2- The slopes    = \n",
      "    [ 1.45309559e+03  9.74755608e-01  3.33175209e-01  6.45745332e+00\n",
      " -3.71798322e+01 -9.64423559e+01  1.06568886e+01 -7.13532304e+00\n",
      " -1.05783619e+02  1.22300158e+01  1.12840865e+01  1.43724129e+01\n",
      "  2.63517808e+01 -4.87209351e+01 -8.19434085e+01 -6.73234749e+01\n",
      " -3.11556207e+01 -3.43964757e+01 -6.44521680e+00 -4.40470969e+01]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Trying to fit with another regressor\n",
    "# Trying the Stochastic Gradient Descent Regressor\n",
    "\n",
    "\n",
    "# Select X features, with Removing the Gauge Features\n",
    "data_X = df[[x for x in list(df) if x[:5]!='Gauge']].drop(['Reference', 'Consumption'], axis=1)\n",
    "\n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']\n",
    "\n",
    "# Apply the model\n",
    "output_R = perform_fitting_one_model(data_X, data_yR, \n",
    "                         linear_model.SGDRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=2), \n",
    "                                     scale_features=False)\n",
    "coefficients = list(output_R[1])\n",
    "output_C = perform_fitting_one_model(data_X, data_yC, \n",
    "                         linear_model.SGDRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=2), \n",
    "                                     scale_features=False)\n",
    "coefficients += list(output_C[1])    \n",
    "# Saving th output parameters of the SECOND model\n",
    "\n",
    "models_outputs['SGDRegressor over non-Gauge data unnormalized'] =coefficients\n",
    "# Printing results\n",
    "print_results(*coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 4707.37, NNZs: 74, Bias: 552.457842, T: 7820692, Avg. loss: 920.205989\n",
      "Total training time: 3.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5188.20, NNZs: 74, Bias: 504.972008, T: 15641384, Avg. loss: 919.051822\n",
      "Total training time: 6.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5656.16, NNZs: 74, Bias: 514.184430, T: 23462076, Avg. loss: 919.048681\n",
      "Total training time: 9.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5991.21, NNZs: 74, Bias: 502.269748, T: 31282768, Avg. loss: 918.902525\n",
      "Total training time: 13.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6315.73, NNZs: 74, Bias: 496.790036, T: 39103460, Avg. loss: 918.834090\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6584.06, NNZs: 74, Bias: 508.514550, T: 46924152, Avg. loss: 918.873805\n",
      "Total training time: 19.55 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6856.74, NNZs: 74, Bias: 498.245882, T: 54744844, Avg. loss: 918.792348\n",
      "Total training time: 22.72 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7061.45, NNZs: 74, Bias: 509.609632, T: 62565536, Avg. loss: 918.748813\n",
      "Total training time: 25.90 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7250.38, NNZs: 74, Bias: 525.917431, T: 70386228, Avg. loss: 918.809264\n",
      "Total training time: 29.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7393.47, NNZs: 74, Bias: 539.184006, T: 78206920, Avg. loss: 918.726057\n",
      "Total training time: 32.23 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7547.76, NNZs: 74, Bias: 547.466375, T: 86027612, Avg. loss: 918.704691\n",
      "Total training time: 35.37 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7687.46, NNZs: 74, Bias: 542.449234, T: 93848304, Avg. loss: 918.769737\n",
      "Total training time: 38.51 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7761.52, NNZs: 74, Bias: 523.621830, T: 101668996, Avg. loss: 918.761275\n",
      "Total training time: 41.67 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7882.39, NNZs: 74, Bias: 559.944998, T: 109489688, Avg. loss: 918.720518\n",
      "Total training time: 44.82 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 7950.24, NNZs: 74, Bias: 541.885606, T: 117310380, Avg. loss: 918.740195\n",
      "Total training time: 48.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8044.36, NNZs: 74, Bias: 531.036715, T: 125131072, Avg. loss: 918.698706\n",
      "Total training time: 51.25 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8105.93, NNZs: 74, Bias: 557.597494, T: 132951764, Avg. loss: 918.714511\n",
      "Total training time: 54.42 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8215.02, NNZs: 74, Bias: 564.200367, T: 140772456, Avg. loss: 918.706785\n",
      "Total training time: 57.63 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8303.09, NNZs: 74, Bias: 555.163363, T: 148593148, Avg. loss: 918.715454\n",
      "Total training time: 60.86 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8346.07, NNZs: 74, Bias: 546.250934, T: 156413840, Avg. loss: 918.743164\n",
      "Total training time: 64.07 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8435.75, NNZs: 74, Bias: 545.391250, T: 164234532, Avg. loss: 918.672249\n",
      "Total training time: 67.31 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 8527.99, NNZs: 74, Bias: 555.253127, T: 172055224, Avg. loss: 918.699158\n",
      "Total training time: 70.55 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8599.19, NNZs: 74, Bias: 537.438284, T: 179875916, Avg. loss: 918.690601\n",
      "Total training time: 73.75 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8641.09, NNZs: 74, Bias: 535.483840, T: 187696608, Avg. loss: 918.653436\n",
      "Total training time: 76.96 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8705.00, NNZs: 74, Bias: 578.376860, T: 195517300, Avg. loss: 918.739946\n",
      "Total training time: 80.18 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8769.04, NNZs: 74, Bias: 558.274329, T: 203337992, Avg. loss: 918.713264\n",
      "Total training time: 83.35 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8853.30, NNZs: 74, Bias: 553.289026, T: 211158684, Avg. loss: 918.746722\n",
      "Total training time: 86.64 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8907.32, NNZs: 74, Bias: 559.140453, T: 218979376, Avg. loss: 918.750841\n",
      "Total training time: 90.17 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8985.17, NNZs: 74, Bias: 553.991308, T: 226800068, Avg. loss: 918.679480\n",
      "Total training time: 93.55 seconds.\n",
      "Convergence after 29 epochs took 93.55 seconds\n",
      "121.23519158363342\n",
      "The elapsed time for the test is 0:02:01.235192\n",
      "-- Epoch 1\n",
      "Norm: 171.24, NNZs: 74, Bias: -16.280991, T: 7820692, Avg. loss: 13.508582\n",
      "Total training time: 3.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 234.03, NNZs: 74, Bias: -13.998737, T: 15641384, Avg. loss: 13.506487\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 300.69, NNZs: 74, Bias: -10.797263, T: 23462076, Avg. loss: 13.502988\n",
      "Total training time: 9.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 343.80, NNZs: 74, Bias: -4.817163, T: 31282768, Avg. loss: 13.509483\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 429.90, NNZs: 74, Bias: -4.405583, T: 39103460, Avg. loss: 13.506595\n",
      "Total training time: 15.72 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 519.25, NNZs: 74, Bias: -19.952323, T: 46924152, Avg. loss: 13.500151\n",
      "Total training time: 18.84 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 579.83, NNZs: 74, Bias: -6.694483, T: 54744844, Avg. loss: 13.510667\n",
      "Total training time: 21.96 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 654.31, NNZs: 74, Bias: 0.615671, T: 62565536, Avg. loss: 13.504403\n",
      "Total training time: 25.13 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 728.32, NNZs: 74, Bias: -2.380957, T: 70386228, Avg. loss: 13.502662\n",
      "Total training time: 28.27 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 809.98, NNZs: 74, Bias: 2.159482, T: 78206920, Avg. loss: 13.497743\n",
      "Total training time: 31.40 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 886.61, NNZs: 74, Bias: -2.624025, T: 86027612, Avg. loss: 13.498573\n",
      "Total training time: 34.58 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 963.46, NNZs: 74, Bias: 3.704079, T: 93848304, Avg. loss: 13.495751\n",
      "Total training time: 37.75 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1041.46, NNZs: 74, Bias: 7.259461, T: 101668996, Avg. loss: 13.495559\n",
      "Total training time: 40.91 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1120.34, NNZs: 74, Bias: 6.628913, T: 109489688, Avg. loss: 13.498503\n",
      "Total training time: 44.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1199.12, NNZs: 74, Bias: -0.244596, T: 117310380, Avg. loss: 13.497753\n",
      "Total training time: 47.16 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1270.95, NNZs: 74, Bias: 15.258421, T: 125131072, Avg. loss: 13.497468\n",
      "Total training time: 50.28 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1349.60, NNZs: 74, Bias: 10.571508, T: 132951764, Avg. loss: 13.488340\n",
      "Total training time: 53.54 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1426.44, NNZs: 74, Bias: 12.987843, T: 140772456, Avg. loss: 13.497594\n",
      "Total training time: 56.86 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1502.10, NNZs: 74, Bias: 12.755406, T: 148593148, Avg. loss: 13.492582\n",
      "Total training time: 60.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1579.44, NNZs: 74, Bias: 11.132910, T: 156413840, Avg. loss: 13.487606\n",
      "Total training time: 63.16 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1654.35, NNZs: 74, Bias: 19.108522, T: 164234532, Avg. loss: 13.496459\n",
      "Total training time: 66.31 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1728.72, NNZs: 74, Bias: 22.331594, T: 172055224, Avg. loss: 13.491161\n",
      "Total training time: 69.46 seconds.\n",
      "Convergence after 22 epochs took 69.46 seconds\n",
      "94.1407470703125\n",
      "The elapsed time for the test is 0:01:34.140747\n",
      "\n",
      "    The metrics for training and testing datasets are:\n",
      "    Feature        Dataset      The MSE            the r2\n",
      "    ==========================================================\n",
      "    Reference      Training     36141401.20       02.16%\n",
      "    Reference      Testing      36101621.63       02.13%\n",
      "    Consumption    Training        25359.95       08.13%\n",
      "    Consumption    Testing         22230.80       07.93%\n",
      "    ==========================================================\n",
      "\n",
      "    For the **Reference** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [553.99130827]\n",
      "        2- The slopes    = \n",
      "    [ 2.08028684e+03  1.45508177e+01  4.58573031e+00  1.36299888e+02\n",
      " -6.88979437e+01  2.15871992e+02  7.76969024e+00 -8.02787847e+00\n",
      "  1.53946816e+02  2.17821443e+02  8.17386271e+01  2.95922705e+01\n",
      "  1.55304422e+02  1.95598921e+02  2.06462146e+02 -3.37418059e+00\n",
      " -1.10177538e+02 -1.09991717e+02  5.39492974e+02 -1.27098979e+02\n",
      "  4.54247519e+02  7.25287445e+02 -3.01940892e+02 -1.56978249e+03\n",
      "  6.06125170e+01 -5.86842595e+02 -1.64627355e+03  3.48743438e+01\n",
      " -1.29649396e+02 -2.63934216e+02  7.58503124e+02 -7.17156609e+02\n",
      "  7.66083416e+02  4.61744699e+03  3.57588961e+02 -1.13519421e+03\n",
      " -6.22010424e+02 -6.05971870e+02  6.80229090e+02  1.55615624e+02\n",
      "  7.63325230e+01  1.79800000e+03  1.16000000e+02 -1.17643560e+03\n",
      "  8.45387046e+02 -1.44849581e+03 -2.36976505e+01 -1.06893281e+03\n",
      "  4.42391421e+02  1.74000000e+03 -1.70726552e+03 -7.67256555e+02\n",
      "  1.49530091e+03  4.82523875e+02  7.60437412e+01  4.60361196e+02\n",
      "  6.66893397e+02 -1.55955889e+03 -1.03506753e+03  1.65300000e+03\n",
      " -1.43999307e+03 -1.40073543e+03 -2.19076288e+02 -1.70991720e+03\n",
      "  6.94523938e+02  7.10731201e+02  1.91839300e+03  7.86177151e+02\n",
      "  9.43334504e+02  9.99479239e+02  6.29689807e+02 -1.54820087e+03\n",
      " -5.99961741e+02 -1.30770948e+03]\n",
      "    and For the **Consumption** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [22.33159435]\n",
      "        2- The slopes    = \n",
      "    [ 1.21537842e+02 -7.29766812e-01  1.05693690e+00  4.28414382e-01\n",
      "  5.73955446e-01  1.31417117e+01 -1.38433193e+01 -1.61051027e+01\n",
      "  1.09404107e+01 -1.10467752e+01 -1.23616431e+01 -1.52627118e+01\n",
      "  1.19920569e+01  6.76801774e+00 -8.65111464e-01  4.43663118e+00\n",
      " -3.88063160e+00 -9.45304443e+00  3.20034806e+01 -7.46515566e+00\n",
      " -4.63992920e+01 -4.64016054e+01  2.96597766e+01 -4.62517435e+01\n",
      " -5.43416478e+01 -4.94442804e+01 -4.80665043e+01 -4.85145208e+01\n",
      " -4.84137872e+01 -4.65480010e+01 -4.36734388e+01 -4.23803322e+01\n",
      " -4.71497640e+01 -3.26539319e+01 -4.43670664e+01 -4.68025673e+01\n",
      " -4.68248033e+01 -3.63033182e+01 -4.90974781e+01 -4.51882285e+01\n",
      " -4.06517712e+01 -2.88463334e+01 -7.57569906e+01 -5.50730525e+01\n",
      " -4.88168621e+01 -7.38055533e+01 -3.51640800e+01 -4.23032466e+01\n",
      " -4.39346609e+01  1.32000000e+03 -5.08344835e+01 -4.96822938e+01\n",
      " -4.48255655e+01 -4.51115172e+01 -4.67649983e+01 -4.31009785e+01\n",
      " -5.28482767e+01 -4.20495906e+01 -4.31792911e+01  1.05523398e+03\n",
      " -4.13294020e+01 -4.45123792e+01 -4.10354974e+01 -4.47699997e+01\n",
      " -4.78268940e+01 -5.15321475e+01 -4.32423805e+01 -5.26347454e+01\n",
      " -5.18920215e+01 -4.77618700e+01 -4.63409196e+01 -5.19493252e+01\n",
      " -4.50514730e+01 -4.11112495e+01]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Trying to fit with another regressor\n",
    "# Trying the Passive Aggressive Regressor\n",
    "\n",
    "# Separate the independent features\n",
    "data_X = df.drop(['Reference', 'Consumption'], axis=1) \n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']\n",
    "\n",
    "# Apply the model\n",
    "output_R = perform_fitting_one_model(data_X, data_yR, \n",
    "                         linear_model.PassiveAggressiveRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=1), \n",
    "                                     scale_features=False)\n",
    "coefficients = list(output_R[1])\n",
    "output_C = perform_fitting_one_model(data_X, data_yC, \n",
    "                         linear_model.PassiveAggressiveRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=1), \n",
    "                                     scale_features=False)\n",
    "coefficients += list(output_C[1])    \n",
    "# Saving th output parameters of the SECOND model\n",
    "\n",
    "models_outputs['PassiveAggressiveRegressor over all data unnormalized'] =coefficients\n",
    "# Printing results\n",
    "print_results(*coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2794.79, NNZs: 20, Bias: -431.452611, T: 7820692, Avg. loss: 1242.637807\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2899.48, NNZs: 20, Bias: -470.532913, T: 15641384, Avg. loss: 1242.370200\n",
      "Total training time: 3.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2834.46, NNZs: 20, Bias: -465.428939, T: 23462076, Avg. loss: 1242.252449\n",
      "Total training time: 5.38 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2857.05, NNZs: 20, Bias: -480.846221, T: 31282768, Avg. loss: 1242.330109\n",
      "Total training time: 7.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2763.89, NNZs: 20, Bias: -501.054285, T: 39103460, Avg. loss: 1242.212986\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2836.81, NNZs: 20, Bias: -529.678021, T: 46924152, Avg. loss: 1242.227933\n",
      "Total training time: 10.74 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2847.81, NNZs: 20, Bias: -520.955171, T: 54744844, Avg. loss: 1242.411860\n",
      "Total training time: 12.54 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2838.94, NNZs: 20, Bias: -525.988177, T: 62565536, Avg. loss: 1242.316827\n",
      "Total training time: 14.37 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2885.67, NNZs: 20, Bias: -550.406014, T: 70386228, Avg. loss: 1242.286984\n",
      "Total training time: 16.14 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2804.58, NNZs: 20, Bias: -572.293264, T: 78206920, Avg. loss: 1242.241231\n",
      "Total training time: 17.90 seconds.\n",
      "Convergence after 10 epochs took 17.90 seconds\n",
      "24.735971927642822\n",
      "The elapsed time for the test is 0:00:24.735972\n",
      "-- Epoch 1\n",
      "Norm: 134.89, NNZs: 20, Bias: -14.311955, T: 7820692, Avg. loss: 13.547197\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 173.10, NNZs: 20, Bias: -29.104265, T: 15641384, Avg. loss: 13.546647\n",
      "Total training time: 3.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 138.31, NNZs: 20, Bias: -15.943173, T: 23462076, Avg. loss: 13.547038\n",
      "Total training time: 5.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 151.90, NNZs: 20, Bias: -16.420864, T: 31282768, Avg. loss: 13.548988\n",
      "Total training time: 7.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 140.70, NNZs: 20, Bias: -15.783543, T: 39103460, Avg. loss: 13.549681\n",
      "Total training time: 8.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 132.63, NNZs: 20, Bias: -16.699881, T: 46924152, Avg. loss: 13.550026\n",
      "Total training time: 10.66 seconds.\n",
      "Convergence after 6 epochs took 10.66 seconds\n",
      "17.500282049179077\n",
      "The elapsed time for the test is 0:00:17.500282\n",
      "\n",
      "    The metrics for training and testing datasets are:\n",
      "    Feature        Dataset      The MSE            the r2\n",
      "    ==========================================================\n",
      "    Reference      Training     37255996.81       -0.86%\n",
      "    Reference      Testing      37217573.76       -0.89%\n",
      "    Consumption    Training        26457.05       04.16%\n",
      "    Consumption    Testing         23142.40       04.15%\n",
      "    ==========================================================\n",
      "\n",
      "    For the **Reference** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-572.29326447]\n",
      "        2- The slopes    = \n",
      "    [2570.2086132     8.82648147   -7.49783811   10.95412679  -38.8012384\n",
      "   13.94726158  165.30733644 -304.83814824  325.29832017  382.16966854\n",
      "  109.5528793  -122.56211611 -273.18956148   79.02596098  -31.60323601\n",
      " -346.52642796 -418.29131693 -191.50957656  610.71119058 -268.41076407]\n",
      "    and For the **Consumption** feature\n",
      "    The fitting coeefficients are:\n",
      "        1- The intercept = [-16.69988123]\n",
      "        2- The slopes    = \n",
      "    [124.36393257   0.20783572  -0.38917176   4.10572904   2.62925802\n",
      "   6.85772968 -15.08850073 -10.80442011   7.18777745  -7.0479437\n",
      " -11.38336187 -13.94815275   2.19603577  -2.56919623 -12.41673474\n",
      "  -3.90998603 -11.226169   -11.98414031  26.9717663  -10.24063925]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Trying to fit with another regressor\n",
    "# Trying the Passive Aggressive Regressor\n",
    "\n",
    "# Select X features, with Removing the Gauge Features\n",
    "data_X = df[[x for x in list(df) if x[:5]!='Gauge']].drop(['Reference', 'Consumption'], axis=1)\n",
    "# The first dependent feature\n",
    "data_yR = df['Reference']\n",
    "# The second dependent feature\n",
    "data_yC = df['Consumption']\n",
    "\n",
    "# Apply the model\n",
    "output_R = perform_fitting_one_model(data_X, data_yR, \n",
    "                         linear_model.PassiveAggressiveRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=1), \n",
    "                                     scale_features=False)\n",
    "coefficients = list(output_R[1])\n",
    "output_C = perform_fitting_one_model(data_X, data_yC, \n",
    "                         linear_model.PassiveAggressiveRegressor(max_iter=50, \n",
    "                                                   tol=1e-3, \n",
    "                                                   verbose=1), \n",
    "                                     scale_features=False)\n",
    "coefficients += list(output_C[1])    \n",
    "# Saving th output parameters of the SECOND model\n",
    "\n",
    "models_outputs['PassiveAggressiveRegressor over non-Gauge data unnormalized'] =coefficients\n",
    "# Printing results\n",
    "print_results(*coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear with all variables non normalized ': (-64874898147096.64,\n",
       "  array([ 1.06584295e+04,  5.78937534e-01,  5.68323124e-02,  7.14158468e+02,\n",
       "          3.97075552e+03,  5.52286459e+03,  1.04651857e+03,  9.86140430e+02,\n",
       "          3.25084202e+03,  1.61349906e+03,  1.78427096e+03,  1.32940154e+03,\n",
       "          4.01888821e+13,  4.31375301e+13,  4.01888821e+13,  4.31375301e+13,\n",
       "         -2.94864803e+12, -2.94864803e+12, -2.94864803e+12, -2.94864803e+12,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860164e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13]),\n",
       "  34721242.460709,\n",
       "  0.06005116081177153,\n",
       "  34736285.83864402,\n",
       "  0.0583237760896782,\n",
       "  1284515300540.056,\n",
       "  array([ 3.08266541e+02, -3.05495685e-01,  6.45531356e-02,  4.43831078e+00,\n",
       "          9.58474991e+00, -6.83778737e+01, -1.38039060e+02, -1.19025650e+02,\n",
       "          1.63639132e+01, -1.31059073e+02, -1.34912716e+02, -1.36104402e+02,\n",
       "         -9.01678331e+10,  5.94428941e+11, -9.01678331e+10,  5.94428941e+11,\n",
       "         -6.84596774e+11, -6.84596774e+11, -6.84596774e+11, -6.84596774e+11,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434742e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434746e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12]),\n",
       "  6672.025947749766,\n",
       "  0.7583028926100472,\n",
       "  6867.607786410363,\n",
       "  0.715563500101682),\n",
       " 'Linear with non-Gauge variables normalized': [28862222325123.113,\n",
       "  array([ 1.17349426e+04,  9.46150480e+02,  7.88293510e+01,  6.29363615e+02,\n",
       "          5.00882389e+03,  8.17339927e+03,  2.97325523e+03,  1.98265450e+03,\n",
       "          5.50506795e+03,  3.54109150e+03,  3.61524336e+03,  3.01788609e+03,\n",
       "         -2.88622223e+13,  3.94432581e+12, -2.88622223e+13,  3.94432581e+12,\n",
       "         -3.28065482e+13, -3.28065482e+13, -3.28065482e+13, -3.28065482e+13,\n",
       "         -2.58952550e+00]),\n",
       "  36191634.274272844,\n",
       "  0.020245756962090633,\n",
       "  36175800.028041266,\n",
       "  0.019299561110744712,\n",
       "  1525699085810.638,\n",
       "  array([ 1.44031795e+03,  3.55339931e+01,  3.06404930e+00,  4.55372493e+00,\n",
       "         -2.63172772e+01,  1.59088565e+02,  2.91992877e+02,  2.68715883e+02,\n",
       "         -8.93407546e+01,  2.95981545e+02,  2.94118358e+02,  2.98323215e+02,\n",
       "         -1.52569909e+12, -2.14011093e+11, -1.52569909e+12, -2.14011093e+11,\n",
       "         -1.31168799e+12, -1.31168799e+12, -1.31168799e+12, -1.31168799e+12,\n",
       "         -9.81730421e-02]),\n",
       "  20688.019196625595,\n",
       "  0.250567303453216,\n",
       "  18840.003576258016,\n",
       "  0.21970140957866013],\n",
       " 'SGDRegressor over all data unnormalized': [array([-4020.85235125]),\n",
       "  array([ 1.15755898e+04, -6.74443862e+00, -1.47230964e+01,  5.08430899e+02,\n",
       "          3.36946877e+03,  3.85339778e+03, -6.22481878e+02, -1.07628527e+03,\n",
       "          3.90843405e+03, -2.11309707e+02, -2.94028616e+01, -4.83855475e+02,\n",
       "          5.84309093e+03, -1.53202680e+03, -2.87636572e+03, -1.73178769e+03,\n",
       "         -1.35398262e+03, -1.04712966e+03,  5.00605887e+02, -1.36330810e+03,\n",
       "          3.54070200e+02,  1.35226531e+02, -6.39340410e+03, -1.67006168e+03,\n",
       "         -2.10602870e+02, -6.60214827e+02, -4.90180195e+02, -6.48907842e+01,\n",
       "         -9.12683210e+01, -3.57374146e+02,  3.52200463e+02, -1.02791549e+02,\n",
       "          4.10273769e+02,  8.96330309e+02,  1.31628610e+02, -1.07253560e+03,\n",
       "         -7.76982506e+02, -2.03065281e+03,  4.02035610e+01, -2.52197744e+02,\n",
       "         -1.76534239e+02,  2.06874120e+02, -4.34048096e+02, -2.28912821e+02,\n",
       "         -1.73926014e+02, -2.84878260e+02, -2.99795831e+01, -1.28827066e+03,\n",
       "          6.17620256e+01, -3.93182756e+03, -8.71440419e+02, -7.46506995e+02,\n",
       "          4.70643122e+02,  1.10091933e+01,  2.27042153e+02,  1.22934701e+02,\n",
       "          8.65502267e+02, -2.45464899e+02,  3.14889015e+02,  2.13527950e+04,\n",
       "         -1.40854003e+02, -1.17596336e+03, -4.08457095e+01, -2.29049117e+03,\n",
       "          6.52468305e+02,  1.13307792e+02,  7.50822020e+02, -3.41340320e+02,\n",
       "          1.04319559e+01,  6.60794432e+02,  8.85207792e+01, -7.84431845e+02,\n",
       "         -7.83117135e+01, -1.08963477e+03]),\n",
       "  35455202.34294234,\n",
       "  0.040181919666480215,\n",
       "  35445711.46558487,\n",
       "  0.039091747408601774,\n",
       "  array([-577.78835603]),\n",
       "  array([ 1.39213375e+03, -3.17517393e-01, -2.33825013e-01,  9.04463104e+00,\n",
       "         -4.07489424e+01, -6.98958196e+01,  2.54546961e+01,  1.64760871e+01,\n",
       "         -8.09866349e+01,  3.71590803e+01,  3.33835311e+01,  3.64806654e+01,\n",
       "          6.93020518e+01, -2.13204916e+01, -4.23911030e+01, -3.55862567e+01,\n",
       "         -1.78182032e+01, -2.32613908e+01,  1.35317651e+01, -2.93589193e+01,\n",
       "         -7.32494504e+01, -4.57606353e+01, -3.76635803e+02, -3.17522295e+01,\n",
       "         -2.52985164e+01, -4.26270355e+01, -9.00245921e+00, -5.26333267e+01,\n",
       "         -9.03513449e+00, -3.76035513e+01, -2.74194867e+01, -3.15095307e+00,\n",
       "         -4.94219924e+01, -2.17236796e+02, -5.20229717e+01, -4.80726394e+01,\n",
       "         -5.25695514e+01, -2.29302939e+02, -6.16540446e+00, -4.64085585e+01,\n",
       "         -2.66603375e+01, -2.06250900e+00, -5.68582352e+01, -5.89201261e+00,\n",
       "         -1.08589934e+02, -2.32084881e+01, -2.90609840e+00, -5.47222152e+01,\n",
       "         -5.51248988e+01,  2.67456512e+03, -1.63916279e+01, -3.52281798e+01,\n",
       "         -2.18476009e+01, -5.06835910e+00, -4.34050610e+01, -4.74059598e+01,\n",
       "         -6.11212258e+01, -5.81440180e+00, -7.56536361e+00, -6.99043989e+01,\n",
       "         -2.57231446e+00, -4.82068623e+01, -7.16445330e+00, -4.82358832e+01,\n",
       "         -4.88486057e+01, -2.86159428e+01, -2.51453428e+01, -1.70320157e+02,\n",
       "         -3.36827440e+01, -1.07983904e+02, -4.68643194e+01, -1.53566244e+01,\n",
       "         -3.98060176e+00, -3.24368225e+01]),\n",
       "  18982.313244273188,\n",
       "  0.31235726020247634,\n",
       "  17383.11398500062,\n",
       "  0.2800415729897894],\n",
       " 'PassiveAggressiveRegressor over all data unnormalized': [array([553.99130827]),\n",
       "  array([ 2.08028684e+03,  1.45508177e+01,  4.58573031e+00,  1.36299888e+02,\n",
       "         -6.88979437e+01,  2.15871992e+02,  7.76969024e+00, -8.02787847e+00,\n",
       "          1.53946816e+02,  2.17821443e+02,  8.17386271e+01,  2.95922705e+01,\n",
       "          1.55304422e+02,  1.95598921e+02,  2.06462146e+02, -3.37418059e+00,\n",
       "         -1.10177538e+02, -1.09991717e+02,  5.39492974e+02, -1.27098979e+02,\n",
       "          4.54247519e+02,  7.25287445e+02, -3.01940892e+02, -1.56978249e+03,\n",
       "          6.06125170e+01, -5.86842595e+02, -1.64627355e+03,  3.48743438e+01,\n",
       "         -1.29649396e+02, -2.63934216e+02,  7.58503124e+02, -7.17156609e+02,\n",
       "          7.66083416e+02,  4.61744699e+03,  3.57588961e+02, -1.13519421e+03,\n",
       "         -6.22010424e+02, -6.05971870e+02,  6.80229090e+02,  1.55615624e+02,\n",
       "          7.63325230e+01,  1.79800000e+03,  1.16000000e+02, -1.17643560e+03,\n",
       "          8.45387046e+02, -1.44849581e+03, -2.36976505e+01, -1.06893281e+03,\n",
       "          4.42391421e+02,  1.74000000e+03, -1.70726552e+03, -7.67256555e+02,\n",
       "          1.49530091e+03,  4.82523875e+02,  7.60437412e+01,  4.60361196e+02,\n",
       "          6.66893397e+02, -1.55955889e+03, -1.03506753e+03,  1.65300000e+03,\n",
       "         -1.43999307e+03, -1.40073543e+03, -2.19076288e+02, -1.70991720e+03,\n",
       "          6.94523938e+02,  7.10731201e+02,  1.91839300e+03,  7.86177151e+02,\n",
       "          9.43334504e+02,  9.99479239e+02,  6.29689807e+02, -1.54820087e+03,\n",
       "         -5.99961741e+02, -1.30770948e+03]),\n",
       "  36141401.20207543,\n",
       "  0.02160563104938029,\n",
       "  36101621.62619035,\n",
       "  0.021310485297491355,\n",
       "  array([22.33159435]),\n",
       "  array([ 1.21537842e+02, -7.29766812e-01,  1.05693690e+00,  4.28414382e-01,\n",
       "          5.73955446e-01,  1.31417117e+01, -1.38433193e+01, -1.61051027e+01,\n",
       "          1.09404107e+01, -1.10467752e+01, -1.23616431e+01, -1.52627118e+01,\n",
       "          1.19920569e+01,  6.76801774e+00, -8.65111464e-01,  4.43663118e+00,\n",
       "         -3.88063160e+00, -9.45304443e+00,  3.20034806e+01, -7.46515566e+00,\n",
       "         -4.63992920e+01, -4.64016054e+01,  2.96597766e+01, -4.62517435e+01,\n",
       "         -5.43416478e+01, -4.94442804e+01, -4.80665043e+01, -4.85145208e+01,\n",
       "         -4.84137872e+01, -4.65480010e+01, -4.36734388e+01, -4.23803322e+01,\n",
       "         -4.71497640e+01, -3.26539319e+01, -4.43670664e+01, -4.68025673e+01,\n",
       "         -4.68248033e+01, -3.63033182e+01, -4.90974781e+01, -4.51882285e+01,\n",
       "         -4.06517712e+01, -2.88463334e+01, -7.57569906e+01, -5.50730525e+01,\n",
       "         -4.88168621e+01, -7.38055533e+01, -3.51640800e+01, -4.23032466e+01,\n",
       "         -4.39346609e+01,  1.32000000e+03, -5.08344835e+01, -4.96822938e+01,\n",
       "         -4.48255655e+01, -4.51115172e+01, -4.67649983e+01, -4.31009785e+01,\n",
       "         -5.28482767e+01, -4.20495906e+01, -4.31792911e+01,  1.05523398e+03,\n",
       "         -4.13294020e+01, -4.45123792e+01, -4.10354974e+01, -4.47699997e+01,\n",
       "         -4.78268940e+01, -5.15321475e+01, -4.32423805e+01, -5.26347454e+01,\n",
       "         -5.18920215e+01, -4.77618700e+01, -4.63409196e+01, -5.19493252e+01,\n",
       "         -4.50514730e+01, -4.11112495e+01]),\n",
       "  25359.950467237577,\n",
       "  0.08132451529942908,\n",
       "  22230.803228053224,\n",
       "  0.07926427123165747],\n",
       " 'SGDRegressor over non-Gauge data unnormalized': [array([-5177.29304409]),\n",
       "  array([ 1.14396344e+04,  1.82943292e+02,  6.46953421e+01,  4.40383537e+02,\n",
       "          3.72397981e+03,  3.87304747e+03, -4.01925371e+02, -1.46440200e+03,\n",
       "          4.29017787e+03, -9.20646134e+00,  5.58598543e+01, -5.49403932e+02,\n",
       "          5.85211093e+03, -1.46929379e+03, -2.77399335e+03, -1.95058132e+03,\n",
       "         -1.57564378e+03, -9.96696708e+02,  6.73735995e+02, -1.52127062e+03]),\n",
       "  43797050.94255706,\n",
       "  -0.18564268660343308,\n",
       "  43773973.04866529,\n",
       "  -0.18668155362083017,\n",
       "  array([-613.06271815]),\n",
       "  array([ 1.45309559e+03,  9.74755608e-01,  3.33175209e-01,  6.45745332e+00,\n",
       "         -3.71798322e+01, -9.64423559e+01,  1.06568886e+01, -7.13532304e+00,\n",
       "         -1.05783619e+02,  1.22300158e+01,  1.12840865e+01,  1.43724129e+01,\n",
       "          2.63517808e+01, -4.87209351e+01, -8.19434085e+01, -6.73234749e+01,\n",
       "         -3.11556207e+01, -3.43964757e+01, -6.44521680e+00, -4.40470969e+01]),\n",
       "  20739.554921883304,\n",
       "  0.24870039888486173,\n",
       "  18903.532610885457,\n",
       "  0.21707022026014566],\n",
       " 'PassiveAggressiveRegressor over non-Gauge data unnormalized': [array([-572.29326447]),\n",
       "  array([2570.2086132 ,    8.82648147,   -7.49783811,   10.95412679,\n",
       "          -38.8012384 ,   13.94726158,  165.30733644, -304.83814824,\n",
       "          325.29832017,  382.16966854,  109.5528793 , -122.56211611,\n",
       "         -273.18956148,   79.02596098,  -31.60323601, -346.52642796,\n",
       "         -418.29131693, -191.50957656,  610.71119058, -268.41076407]),\n",
       "  37255996.80975859,\n",
       "  -0.008567910372463405,\n",
       "  37217573.75606029,\n",
       "  -0.008942190322523302,\n",
       "  array([-16.69988123]),\n",
       "  array([124.36393257,   0.20783572,  -0.38917176,   4.10572904,\n",
       "           2.62925802,   6.85772968, -15.08850073, -10.80442011,\n",
       "           7.18777745,  -7.0479437 , -11.38336187, -13.94815275,\n",
       "           2.19603577,  -2.56919623, -12.41673474,  -3.90998603,\n",
       "         -11.226169  , -11.98414031,  26.9717663 , -10.24063925]),\n",
       "  26457.051261077595,\n",
       "  0.04158155109891004,\n",
       "  23142.39713064388,\n",
       "  0.041508681942673986]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the outputs to desk\n",
    "np.save('models_outputs.npy', models_outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear with all variables non normalized ': (-64874898147096.64,\n",
       "  array([ 1.06584295e+04,  5.78937534e-01,  5.68323124e-02,  7.14158468e+02,\n",
       "          3.97075552e+03,  5.52286459e+03,  1.04651857e+03,  9.86140430e+02,\n",
       "          3.25084202e+03,  1.61349906e+03,  1.78427096e+03,  1.32940154e+03,\n",
       "          4.01888821e+13,  4.31375301e+13,  4.01888821e+13,  4.31375301e+13,\n",
       "         -2.94864803e+12, -2.94864803e+12, -2.94864803e+12, -2.94864803e+12,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860164e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13,  2.46860160e+13,  2.46860160e+13,\n",
       "          2.46860160e+13,  2.46860160e+13]),\n",
       "  34721242.460709,\n",
       "  0.06005116081177153,\n",
       "  34736285.83864402,\n",
       "  0.0583237760896782,\n",
       "  1284515300540.056,\n",
       "  array([ 3.08266541e+02, -3.05495685e-01,  6.45531356e-02,  4.43831078e+00,\n",
       "          9.58474991e+00, -6.83778737e+01, -1.38039060e+02, -1.19025650e+02,\n",
       "          1.63639132e+01, -1.31059073e+02, -1.34912716e+02, -1.36104402e+02,\n",
       "         -9.01678331e+10,  5.94428941e+11, -9.01678331e+10,  5.94428941e+11,\n",
       "         -6.84596774e+11, -6.84596774e+11, -6.84596774e+11, -6.84596774e+11,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434742e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434746e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12, -1.19434747e+12, -1.19434747e+12,\n",
       "         -1.19434747e+12, -1.19434747e+12]),\n",
       "  6672.025947749766,\n",
       "  0.7583028926100472,\n",
       "  6867.607786410363,\n",
       "  0.715563500101682),\n",
       " 'Linear with non-Gauge variables normalized': [28862222325123.113,\n",
       "  array([ 1.17349426e+04,  9.46150480e+02,  7.88293510e+01,  6.29363615e+02,\n",
       "          5.00882389e+03,  8.17339927e+03,  2.97325523e+03,  1.98265450e+03,\n",
       "          5.50506795e+03,  3.54109150e+03,  3.61524336e+03,  3.01788609e+03,\n",
       "         -2.88622223e+13,  3.94432581e+12, -2.88622223e+13,  3.94432581e+12,\n",
       "         -3.28065482e+13, -3.28065482e+13, -3.28065482e+13, -3.28065482e+13,\n",
       "         -2.58952550e+00]),\n",
       "  36191634.274272844,\n",
       "  0.020245756962090633,\n",
       "  36175800.028041266,\n",
       "  0.019299561110744712,\n",
       "  1525699085810.638,\n",
       "  array([ 1.44031795e+03,  3.55339931e+01,  3.06404930e+00,  4.55372493e+00,\n",
       "         -2.63172772e+01,  1.59088565e+02,  2.91992877e+02,  2.68715883e+02,\n",
       "         -8.93407546e+01,  2.95981545e+02,  2.94118358e+02,  2.98323215e+02,\n",
       "         -1.52569909e+12, -2.14011093e+11, -1.52569909e+12, -2.14011093e+11,\n",
       "         -1.31168799e+12, -1.31168799e+12, -1.31168799e+12, -1.31168799e+12,\n",
       "         -9.81730421e-02]),\n",
       "  20688.019196625595,\n",
       "  0.250567303453216,\n",
       "  18840.003576258016,\n",
       "  0.21970140957866013],\n",
       " 'SGDRegressor over all data unnormalized': [array([-4020.85235125]),\n",
       "  array([ 1.15755898e+04, -6.74443862e+00, -1.47230964e+01,  5.08430899e+02,\n",
       "          3.36946877e+03,  3.85339778e+03, -6.22481878e+02, -1.07628527e+03,\n",
       "          3.90843405e+03, -2.11309707e+02, -2.94028616e+01, -4.83855475e+02,\n",
       "          5.84309093e+03, -1.53202680e+03, -2.87636572e+03, -1.73178769e+03,\n",
       "         -1.35398262e+03, -1.04712966e+03,  5.00605887e+02, -1.36330810e+03,\n",
       "          3.54070200e+02,  1.35226531e+02, -6.39340410e+03, -1.67006168e+03,\n",
       "         -2.10602870e+02, -6.60214827e+02, -4.90180195e+02, -6.48907842e+01,\n",
       "         -9.12683210e+01, -3.57374146e+02,  3.52200463e+02, -1.02791549e+02,\n",
       "          4.10273769e+02,  8.96330309e+02,  1.31628610e+02, -1.07253560e+03,\n",
       "         -7.76982506e+02, -2.03065281e+03,  4.02035610e+01, -2.52197744e+02,\n",
       "         -1.76534239e+02,  2.06874120e+02, -4.34048096e+02, -2.28912821e+02,\n",
       "         -1.73926014e+02, -2.84878260e+02, -2.99795831e+01, -1.28827066e+03,\n",
       "          6.17620256e+01, -3.93182756e+03, -8.71440419e+02, -7.46506995e+02,\n",
       "          4.70643122e+02,  1.10091933e+01,  2.27042153e+02,  1.22934701e+02,\n",
       "          8.65502267e+02, -2.45464899e+02,  3.14889015e+02,  2.13527950e+04,\n",
       "         -1.40854003e+02, -1.17596336e+03, -4.08457095e+01, -2.29049117e+03,\n",
       "          6.52468305e+02,  1.13307792e+02,  7.50822020e+02, -3.41340320e+02,\n",
       "          1.04319559e+01,  6.60794432e+02,  8.85207792e+01, -7.84431845e+02,\n",
       "         -7.83117135e+01, -1.08963477e+03]),\n",
       "  35455202.34294234,\n",
       "  0.040181919666480215,\n",
       "  35445711.46558487,\n",
       "  0.039091747408601774,\n",
       "  array([-577.78835603]),\n",
       "  array([ 1.39213375e+03, -3.17517393e-01, -2.33825013e-01,  9.04463104e+00,\n",
       "         -4.07489424e+01, -6.98958196e+01,  2.54546961e+01,  1.64760871e+01,\n",
       "         -8.09866349e+01,  3.71590803e+01,  3.33835311e+01,  3.64806654e+01,\n",
       "          6.93020518e+01, -2.13204916e+01, -4.23911030e+01, -3.55862567e+01,\n",
       "         -1.78182032e+01, -2.32613908e+01,  1.35317651e+01, -2.93589193e+01,\n",
       "         -7.32494504e+01, -4.57606353e+01, -3.76635803e+02, -3.17522295e+01,\n",
       "         -2.52985164e+01, -4.26270355e+01, -9.00245921e+00, -5.26333267e+01,\n",
       "         -9.03513449e+00, -3.76035513e+01, -2.74194867e+01, -3.15095307e+00,\n",
       "         -4.94219924e+01, -2.17236796e+02, -5.20229717e+01, -4.80726394e+01,\n",
       "         -5.25695514e+01, -2.29302939e+02, -6.16540446e+00, -4.64085585e+01,\n",
       "         -2.66603375e+01, -2.06250900e+00, -5.68582352e+01, -5.89201261e+00,\n",
       "         -1.08589934e+02, -2.32084881e+01, -2.90609840e+00, -5.47222152e+01,\n",
       "         -5.51248988e+01,  2.67456512e+03, -1.63916279e+01, -3.52281798e+01,\n",
       "         -2.18476009e+01, -5.06835910e+00, -4.34050610e+01, -4.74059598e+01,\n",
       "         -6.11212258e+01, -5.81440180e+00, -7.56536361e+00, -6.99043989e+01,\n",
       "         -2.57231446e+00, -4.82068623e+01, -7.16445330e+00, -4.82358832e+01,\n",
       "         -4.88486057e+01, -2.86159428e+01, -2.51453428e+01, -1.70320157e+02,\n",
       "         -3.36827440e+01, -1.07983904e+02, -4.68643194e+01, -1.53566244e+01,\n",
       "         -3.98060176e+00, -3.24368225e+01]),\n",
       "  18982.313244273188,\n",
       "  0.31235726020247634,\n",
       "  17383.11398500062,\n",
       "  0.2800415729897894],\n",
       " 'PassiveAggressiveRegressor over all data unnormalized': [array([553.99130827]),\n",
       "  array([ 2.08028684e+03,  1.45508177e+01,  4.58573031e+00,  1.36299888e+02,\n",
       "         -6.88979437e+01,  2.15871992e+02,  7.76969024e+00, -8.02787847e+00,\n",
       "          1.53946816e+02,  2.17821443e+02,  8.17386271e+01,  2.95922705e+01,\n",
       "          1.55304422e+02,  1.95598921e+02,  2.06462146e+02, -3.37418059e+00,\n",
       "         -1.10177538e+02, -1.09991717e+02,  5.39492974e+02, -1.27098979e+02,\n",
       "          4.54247519e+02,  7.25287445e+02, -3.01940892e+02, -1.56978249e+03,\n",
       "          6.06125170e+01, -5.86842595e+02, -1.64627355e+03,  3.48743438e+01,\n",
       "         -1.29649396e+02, -2.63934216e+02,  7.58503124e+02, -7.17156609e+02,\n",
       "          7.66083416e+02,  4.61744699e+03,  3.57588961e+02, -1.13519421e+03,\n",
       "         -6.22010424e+02, -6.05971870e+02,  6.80229090e+02,  1.55615624e+02,\n",
       "          7.63325230e+01,  1.79800000e+03,  1.16000000e+02, -1.17643560e+03,\n",
       "          8.45387046e+02, -1.44849581e+03, -2.36976505e+01, -1.06893281e+03,\n",
       "          4.42391421e+02,  1.74000000e+03, -1.70726552e+03, -7.67256555e+02,\n",
       "          1.49530091e+03,  4.82523875e+02,  7.60437412e+01,  4.60361196e+02,\n",
       "          6.66893397e+02, -1.55955889e+03, -1.03506753e+03,  1.65300000e+03,\n",
       "         -1.43999307e+03, -1.40073543e+03, -2.19076288e+02, -1.70991720e+03,\n",
       "          6.94523938e+02,  7.10731201e+02,  1.91839300e+03,  7.86177151e+02,\n",
       "          9.43334504e+02,  9.99479239e+02,  6.29689807e+02, -1.54820087e+03,\n",
       "         -5.99961741e+02, -1.30770948e+03]),\n",
       "  36141401.20207543,\n",
       "  0.02160563104938029,\n",
       "  36101621.62619035,\n",
       "  0.021310485297491355,\n",
       "  array([22.33159435]),\n",
       "  array([ 1.21537842e+02, -7.29766812e-01,  1.05693690e+00,  4.28414382e-01,\n",
       "          5.73955446e-01,  1.31417117e+01, -1.38433193e+01, -1.61051027e+01,\n",
       "          1.09404107e+01, -1.10467752e+01, -1.23616431e+01, -1.52627118e+01,\n",
       "          1.19920569e+01,  6.76801774e+00, -8.65111464e-01,  4.43663118e+00,\n",
       "         -3.88063160e+00, -9.45304443e+00,  3.20034806e+01, -7.46515566e+00,\n",
       "         -4.63992920e+01, -4.64016054e+01,  2.96597766e+01, -4.62517435e+01,\n",
       "         -5.43416478e+01, -4.94442804e+01, -4.80665043e+01, -4.85145208e+01,\n",
       "         -4.84137872e+01, -4.65480010e+01, -4.36734388e+01, -4.23803322e+01,\n",
       "         -4.71497640e+01, -3.26539319e+01, -4.43670664e+01, -4.68025673e+01,\n",
       "         -4.68248033e+01, -3.63033182e+01, -4.90974781e+01, -4.51882285e+01,\n",
       "         -4.06517712e+01, -2.88463334e+01, -7.57569906e+01, -5.50730525e+01,\n",
       "         -4.88168621e+01, -7.38055533e+01, -3.51640800e+01, -4.23032466e+01,\n",
       "         -4.39346609e+01,  1.32000000e+03, -5.08344835e+01, -4.96822938e+01,\n",
       "         -4.48255655e+01, -4.51115172e+01, -4.67649983e+01, -4.31009785e+01,\n",
       "         -5.28482767e+01, -4.20495906e+01, -4.31792911e+01,  1.05523398e+03,\n",
       "         -4.13294020e+01, -4.45123792e+01, -4.10354974e+01, -4.47699997e+01,\n",
       "         -4.78268940e+01, -5.15321475e+01, -4.32423805e+01, -5.26347454e+01,\n",
       "         -5.18920215e+01, -4.77618700e+01, -4.63409196e+01, -5.19493252e+01,\n",
       "         -4.50514730e+01, -4.11112495e+01]),\n",
       "  25359.950467237577,\n",
       "  0.08132451529942908,\n",
       "  22230.803228053224,\n",
       "  0.07926427123165747],\n",
       " 'SGDRegressor over non-Gauge data unnormalized': [array([-5177.29304409]),\n",
       "  array([ 1.14396344e+04,  1.82943292e+02,  6.46953421e+01,  4.40383537e+02,\n",
       "          3.72397981e+03,  3.87304747e+03, -4.01925371e+02, -1.46440200e+03,\n",
       "          4.29017787e+03, -9.20646134e+00,  5.58598543e+01, -5.49403932e+02,\n",
       "          5.85211093e+03, -1.46929379e+03, -2.77399335e+03, -1.95058132e+03,\n",
       "         -1.57564378e+03, -9.96696708e+02,  6.73735995e+02, -1.52127062e+03]),\n",
       "  43797050.94255706,\n",
       "  -0.18564268660343308,\n",
       "  43773973.04866529,\n",
       "  -0.18668155362083017,\n",
       "  array([-613.06271815]),\n",
       "  array([ 1.45309559e+03,  9.74755608e-01,  3.33175209e-01,  6.45745332e+00,\n",
       "         -3.71798322e+01, -9.64423559e+01,  1.06568886e+01, -7.13532304e+00,\n",
       "         -1.05783619e+02,  1.22300158e+01,  1.12840865e+01,  1.43724129e+01,\n",
       "          2.63517808e+01, -4.87209351e+01, -8.19434085e+01, -6.73234749e+01,\n",
       "         -3.11556207e+01, -3.43964757e+01, -6.44521680e+00, -4.40470969e+01]),\n",
       "  20739.554921883304,\n",
       "  0.24870039888486173,\n",
       "  18903.532610885457,\n",
       "  0.21707022026014566],\n",
       " 'PassiveAggressiveRegressor over non-Gauge data unnormalized': [array([-572.29326447]),\n",
       "  array([2570.2086132 ,    8.82648147,   -7.49783811,   10.95412679,\n",
       "          -38.8012384 ,   13.94726158,  165.30733644, -304.83814824,\n",
       "          325.29832017,  382.16966854,  109.5528793 , -122.56211611,\n",
       "         -273.18956148,   79.02596098,  -31.60323601, -346.52642796,\n",
       "         -418.29131693, -191.50957656,  610.71119058, -268.41076407]),\n",
       "  37255996.80975859,\n",
       "  -0.008567910372463405,\n",
       "  37217573.75606029,\n",
       "  -0.008942190322523302,\n",
       "  array([-16.69988123]),\n",
       "  array([124.36393257,   0.20783572,  -0.38917176,   4.10572904,\n",
       "           2.62925802,   6.85772968, -15.08850073, -10.80442011,\n",
       "           7.18777745,  -7.0479437 , -11.38336187, -13.94815275,\n",
       "           2.19603577,  -2.56919623, -12.41673474,  -3.90998603,\n",
       "         -11.226169  , -11.98414031,  26.9717663 , -10.24063925]),\n",
       "  26457.051261077595,\n",
       "  0.04158155109891004,\n",
       "  23142.39713064388,\n",
       "  0.041508681942673986]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the outputs from desk\n",
    "read_dictionary = np.load('models_outputs.npy')\n",
    "read_dictionary.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
